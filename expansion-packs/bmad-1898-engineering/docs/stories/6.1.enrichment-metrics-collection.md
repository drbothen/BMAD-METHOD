# Story 6.1: Enrichment Metrics Collection & Analysis

## Status

- **Epic:** Epic 6 - Observability & Optimization Enhancements
- **Status:** Draft
- **Story Points:** 5
- **Priority:** Medium
- **Created:** 2025-11-08
- **Assigned To:** TBD

## Story

**As a** Security Manager or Process Improvement Lead
**I want** comprehensive metrics collection for the enrichment workflow
**So that** I can analyze analyst performance, identify bottlenecks, and optimize the enrichment process end-to-end

## Context

Story 5.9 documented enrichment metrics as a "future enhancement" with a proposed schema. Story 3.1 implements the security alert enrichment workflow but does not currently log performance metrics. This story closes that gap by implementing metrics collection throughout the enrichment workflow, enabling end-to-end visibility from alert intake to remediation handoff.

**References:**
- Story 5.9 (Metrics Documentation) - Lines 226-250: Proposed enrichment metrics schema
- Story 3.1 (Security Alert Enrichment Workflow) - Workflow implementation
- Task: `tasks/enrich-security-ticket.md` - Enrichment workflow to instrument

## Acceptance Criteria

- [ ] Enrichment workflow logs metrics to `metrics/enrichment-metrics-{date}.jsonl`
- [ ] All 12+ proposed schema fields are captured (workflow_id, ticket_id, analyst, timestamps, etc.)
- [ ] Stage-level timing data collected for bottleneck analysis
- [ ] Perplexity tool usage tracked (search/reason/deep_research counts)
- [ ] Priority assignment and CVSS/EPSS scores captured for correlation analysis
- [ ] JSONL file creation and append logic handles concurrent writes safely
- [ ] Metrics collection does not significantly impact workflow performance (<5% overhead)
- [ ] Example enrichment metrics data generated for testing reporting scripts
- [ ] Integration with existing reporting scripts validated (Story 5.9 custom scripts)
- [ ] Documentation updated with implementation details and examples

## Tasks/Subtasks

### Task 1: Implement Metrics Collection Infrastructure

- [ ] Create `MetricsCollector` class in `workflows/metrics_collector.py`
- [ ] Implement JSONL append with file locking for concurrent safety
- [ ] Create schema validator to ensure all required fields present
- [ ] Add configuration in `config.yaml` for metrics settings (enable/disable, retention)
- [ ] Implement error handling (metrics failures don't block workflow)

### Task 2: Instrument Enrichment Workflow

- [ ] Modify `tasks/enrich-security-ticket.md` to call metrics collector
- [ ] Add stage timing instrumentation (start/end timestamps per stage)
- [ ] Capture Perplexity MCP tool invocations (search/reason/deep_research)
- [ ] Extract priority, CVSS, EPSS, KEV status from enrichment output
- [ ] Log analyst name from workflow context
- [ ] Test metrics collection with sample enrichment runs

### Task 3: Extend Reporting Scripts

- [ ] Create `scripts/enrichment_performance_report.py`
  - Average enrichment time by analyst
  - Stage-level bottleneck analysis
  - Perplexity tool usage patterns
  - Priority distribution trends
- [ ] Integrate enrichment metrics into existing `review_quality_trends.py`
- [ ] Update `generate_sampling_report.py` to include enrichment velocity
- [ ] Test reports with generated sample data

### Task 4: Validate and Document

- [ ] Generate test dataset with 50+ enrichment metric records
- [ ] Execute all reporting scripts with test data
- [ ] Validate metrics schema matches Story 5.9 documentation
- [ ] Update Story 5.9 Dev Notes to change status from "future" to "implemented"
- [ ] Add enrichment metrics examples to Story 5.9 documentation
- [ ] Create test scenario in Story 5.9 Testing section

## Technical Approach

### Metrics Schema Implementation

Implement the schema proposed in Story 5.9:

```jsonl
{
  "workflow_id": "security-alert-enrichment-v1",
  "ticket_id": "AOD-1234",
  "cve_id": "CVE-2024-1234",
  "analyst": "Alex (Security Analyst)",
  "enrichment_date": "2025-11-08T14:30:00Z",
  "total_duration_seconds": 720,
  "stage_durations": {
    "stage1_fetch_ticket": 30,
    "stage2_research_cve": 180,
    "stage3_priority_assessment": 120,
    "stage4_context_analysis": 150,
    "stage5_remediation_guidance": 180,
    "stage6_update_jira": 60
  },
  "perplexity_tool": "reason",
  "perplexity_queries": 3,
  "priority_assigned": "P2",
  "cvss_score": 7.5,
  "epss_score": 0.00234,
  "kev_status": false,
  "sources_cited": 5,
  "mitre_techniques_mapped": 3
}
```

### Instrumentation Points

**In `tasks/enrich-security-ticket.md`:**

```python
from workflows.metrics_collector import EnrichmentMetricsCollector

# Initialize at workflow start
metrics = EnrichmentMetricsCollector(ticket_id, analyst_name)

# Stage 1: Fetch ticket
metrics.start_stage("stage1_fetch_ticket")
# ... existing logic ...
metrics.end_stage("stage1_fetch_ticket")

# Stage 2: Research CVE
metrics.start_stage("stage2_research_cve")
# Track Perplexity calls
perplexity_result = mcp__perplexity__reason(query)
metrics.track_perplexity_call("reason")
# ... existing logic ...
metrics.end_stage("stage2_research_cve")

# ... repeat for all stages ...

# On workflow completion
metrics.finalize(
    priority=enrichment_result.priority,
    cvss_score=enrichment_result.cvss,
    epss_score=enrichment_result.epss,
    kev_status=enrichment_result.kev,
    sources_cited=len(enrichment_result.sources),
    mitre_techniques=len(enrichment_result.attack_techniques)
)
metrics.write()  # Append to JSONL file
```

### Concurrent Write Safety

Use file locking to prevent corruption when multiple enrichments run concurrently:

```python
import fcntl
import json
import os

def append_metric(metric_data, file_path):
    """Safely append metric to JSONL file with file locking"""
    os.makedirs(os.path.dirname(file_path), exist_ok=True)

    with open(file_path, 'a') as f:
        # Acquire exclusive lock
        fcntl.flock(f.fileno(), fcntl.LOCK_EX)
        try:
            f.write(json.dumps(metric_data) + '\n')
        finally:
            # Release lock
            fcntl.flock(f.fileno(), fcntl.LOCK_UN)
```

### Performance Impact Mitigation

- Metrics collection asynchronous where possible
- Failures logged but don't block workflow
- Configuration flag to disable metrics if needed: `config.yaml: metrics.enrichment.enabled: true`

## Integration Points

**Story 3.1 (Enrichment Workflow):**
- Instrument existing workflow stages
- Add metrics collector imports

**Story 5.9 (Metrics Documentation):**
- Update "Future Enhancement" status to "Implemented"
- Add example enrichment metrics data
- Update test scenarios to include enrichment metrics

**Story 3.2 (Review Workflow):**
- Correlation analysis: enrichment time vs review quality score
- Identify if rushed enrichments (low duration) correlate with lower review scores

## Definition of Done

- [ ] Enrichment metrics logged to JSONL with all required fields
- [ ] Stage timing accurately captured for bottleneck analysis
- [ ] Perplexity tool usage tracked
- [ ] File locking prevents concurrent write corruption
- [ ] Performance overhead <5% measured with load testing
- [ ] Sample dataset of 50+ metrics generated
- [ ] Reporting scripts consume enrichment metrics successfully
- [ ] Documentation updated (Story 5.9 + this story)
- [ ] Code reviewed and approved by QA
- [ ] All tests passing

## Dependencies

**Depends On:**
- Story 3.1 (Enrichment Workflow) - Complete ✅
- Story 5.9 (Metrics Documentation) - Complete ✅

**Blocks:**
- Dashboard implementations requiring enrichment metrics
- End-to-end lifecycle analysis (alert → enrichment → review → remediation)

## Risks and Mitigations

| Risk | Impact | Probability | Mitigation |
| --- | --- | --- | --- |
| Metrics collection impacts workflow performance | High | Medium | Make collection async, add kill switch config |
| Concurrent writes corrupt JSONL file | High | Medium | Use file locking (fcntl) |
| Schema changes break existing reports | Medium | Low | Version metrics schema, validate on write |
| Disk space fills up from metrics files | Medium | Medium | Implement retention policy (archive >90 days) |

## Testing Strategy

**Unit Tests:**
- `MetricsCollector` class methods
- JSONL append with file locking
- Schema validation

**Integration Tests:**
- Full enrichment workflow with metrics enabled
- Concurrent enrichment runs (5 parallel workflows)
- Metrics consumed by reporting scripts

**Performance Tests:**
- Measure workflow duration with/without metrics
- Verify <5% overhead target met

**Test Scenarios:**
1. Single enrichment generates valid JSONL record
2. Concurrent enrichments don't corrupt file
3. Metrics disabled via config prevents logging
4. Missing fields trigger validation error (logged but workflow continues)
5. Reporting scripts parse enrichment metrics correctly

## Success Metrics

- **Performance:** <5% workflow overhead from metrics collection
- **Reliability:** 99.9% successful metric writes (failures logged, don't block)
- **Completeness:** 100% of enrichments generate metric records
- **Integration:** All 3 reporting scripts (Story 5.9) consume enrichment metrics

## Notes

This story completes the observability foundation by adding enrichment metrics to complement the existing review metrics (Story 3.2) and review decision metrics (Story 3.4). With all three metric types, teams will have complete end-to-end visibility into the vulnerability management pipeline.

**Future Enhancements:**
- Real-time metrics dashboard (Grafana)
- Anomaly detection for enrichment performance
- Analyst performance trending and coaching insights
- Correlation analysis: enrichment quality vs review outcomes

## Change Log

| Date | Version | Author | Changes |
| --- | --- | --- | --- |
| 2025-11-08 | 1.0 | Quinn (Test Architect) | Initial story outline created from Story 5.9 review recommendations |
