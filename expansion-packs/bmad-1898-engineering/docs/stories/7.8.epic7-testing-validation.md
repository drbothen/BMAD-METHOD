# Story 7.8: Epic 7 Testing and Validation

## Status

Pending

## Story

**As a** QA Engineer,
**I want** comprehensive end-to-end testing of event investigation capabilities,
**so that** I can validate that security analysts can investigate event alerts and reviewers can provide systematic quality feedback.

## Acceptance Criteria

1. End-to-end test with real JIRA ticket (ICS alert investigation and review)
2. Auto-detection logic validated for ICS, IDS, SIEM, and CVE tickets
3. All 7 event investigation checklists validated with scoring accuracy
4. Disposition agreement and disagreement scenarios tested
5. Fact verification tested for IP ownership, geolocation, threat intelligence
6. No regression in existing CVE enrichment and review workflows
7. Performance targets met (event review completes in 15-20 minutes)

## Tasks / Subtasks

- [ ] Create test plan document (AC: 1)
  - [ ] Create `expansion-packs/bmad-1898-engineering/tests/test-plans/epic-7-test-plan.md`
  - [ ] Define test scope, objectives, approach
  - [ ] List test scenarios with expected results
  - [ ] Define success criteria

- [ ] Prepare test data and test tickets (AC: 1, 2)
  - [ ] Create test ticket: ICS alert (Claroty SSH connection)
  - [ ] Create test ticket: IDS alert (Snort signature)
  - [ ] Create test ticket: SIEM alert (Splunk correlation rule)
  - [ ] Prepare mock investigation documents (excellent, good, needs improvement, inadequate)
  - [ ] Prepare CVE enrichment test ticket (regression testing)

- [ ] Test auto-detection logic (AC: 2)
  - [ ] Test detection of ICS alert (Issue Type = "Event Alert", Claroty keyword)
  - [ ] Test detection of IDS alert (Snort, Suricata keywords)
  - [ ] Test detection of SIEM alert (Splunk, QRadar keywords)
  - [ ] Test detection of CVE enrichment (CVE-ID pattern)
  - [ ] Test ambiguous ticket (prompt user to select type)
  - [ ] Test --type=event parameter (force event workflow)
  - [ ] Test --type=cve parameter (force CVE workflow)

- [ ] Test Security Analyst event investigation (AC: 1)
  - [ ] Test \*investigate-event command with ICS alert
  - [ ] Validate alert metadata extraction
  - [ ] Validate network identifier parsing
  - [ ] Validate timeline construction
  - [ ] Validate disposition determination (TP, FP, BTP)
  - [ ] Validate investigation document generation
  - [ ] Validate JIRA update (comment + custom fields)

- [ ] Test Security Reviewer event review (AC: 1, 3, 4)
  - [ ] Test \*review-enrichment with event investigation
  - [ ] Validate execution of 7 event checklists
  - [ ] Validate weighted scoring calculation (Completeness 25%, Accuracy 20%, etc.)
  - [ ] Validate quality classification (Excellent/Good/Needs Improvement/Inadequate)
  - [ ] Test disposition agreement scenario (reviewer agrees with analyst)
  - [ ] Test disposition disagreement scenario (reviewer disagrees with reasoning)
  - [ ] Validate review report generation with disposition assessment
  - [ ] Validate JIRA update with review feedback

- [ ] Test fact verification (AC: 5)
  - [ ] Test IP ownership verification (ASN lookup)
  - [ ] Test geolocation verification
  - [ ] Test threat intelligence lookup (malicious IP)
  - [ ] Test protocol/port validation
  - [ ] Validate Perplexity MCP integration
  - [ ] Validate source citation in verification results

- [ ] Regression testing (AC: 6)
  - [ ] Test CVE enrichment workflow (no changes expected)
  - [ ] Test CVE review workflow (no changes expected)
  - [ ] Validate existing commands still work (*enrich-ticket, *research-cve, \*review-enrichment with CVE)
  - [ ] Validate existing templates still work (security-enrichment-tmpl.yaml, security-review-report-tmpl.yaml)

- [ ] Performance testing (AC: 7)
  - [ ] Measure event investigation duration (target: 10-15 minutes)
  - [ ] Measure event review duration (target: 15-20 minutes)
  - [ ] Compare to CVE enrichment/review performance (ensure parity)
  - [ ] Identify performance bottlenecks if targets not met

- [ ] Integration testing
  - [ ] Test Atlassian JIRA MCP integration (read/write tickets)
  - [ ] Test Perplexity MCP integration (threat intel, IP lookups)
  - [ ] Test error handling for MCP failures (timeouts, connection errors)

- [ ] Create test execution report (AC: 1)
  - [ ] Document test results for all scenarios
  - [ ] Identify any defects or gaps
  - [ ] Provide pass/fail status for each acceptance criterion
  - [ ] Recommend story completion or additional work

## Dev Notes

### Epic Context

**Epic 7: Security Event Investigation Review Capability**

This story validates that all Epic 7 functionality works end-to-end with real JIRA tickets, ensuring the security analyst can investigate event alerts and the security reviewer can provide systematic quality feedback.

**Related Stories:**

- Story 7.1-7.7: All stories tested in this story
- **Story 7.8: Epic 7 Testing and Validation** (This story)

### Test Scope

**In Scope:**

- Security Analyst event investigation workflow (\*investigate-event)
- Security Reviewer event review workflow (\*review-enrichment with events)
- Auto-detection logic (ICS/IDS/SIEM/CVE)
- 7 event investigation quality checklists
- Event investigation review report template
- Disposition agreement/disagreement tracking
- Fact verification for event claims
- Regression testing (CVE workflows unchanged)

**Out of Scope:**

- Full incident response playbook testing (separate epic)
- Performance optimization (if targets not met, defer to future story)
- UI/UX improvements (command-line interface only)

### Test Scenarios

**Scenario 1: ICS Alert Investigation (AOD-4052)**

- Ticket: Claroty ICS Alert - SSH Connection in Control Environments
- Expected Disposition: False Positive (authorized maintenance)
- Expected Duration: 10-15 minutes for investigation
- Validation: Investigation document generated, JIRA updated, disposition correct

**Scenario 2: IDS Alert Investigation**

- Ticket: Snort Alert - ET EXPLOIT Known Malicious Traffic
- Expected Disposition: True Positive (confirmed exploit attempt)
- Expected Duration: 10-15 minutes for investigation
- Validation: Evidence collected, disposition reasoning clear, escalation recommended

**Scenario 3: SIEM Alert Investigation**

- Ticket: Splunk Notable - Multiple Failed Logins Followed by Success
- Expected Disposition: Benign True Positive (user password change)
- Expected Duration: 10-15 minutes for investigation
- Validation: Alternative explanations considered, confidence level stated

**Scenario 4: Event Investigation Review (Excellent Quality)**

- Investigation: Complete, accurate, well-reasoned (90%+ score)
- Expected: Quality classification = Excellent, no critical issues
- Expected Duration: 15-20 minutes for review
- Validation: Review report acknowledges strengths, minor improvements only

**Scenario 5: Event Investigation Review (Needs Improvement)**

- Investigation: Missing evidence, weak reasoning (60-74% score)
- Expected: Quality classification = Needs Improvement, significant gaps identified
- Expected Duration: 15-20 minutes for review
- Validation: Constructive feedback provided, learning resources linked

**Scenario 6: Disposition Disagreement**

- Analyst Disposition: False Positive
- Reviewer Disposition: True Positive
- Expected: Reviewer provides detailed reasoning with evidence
- Validation: Disposition assessment section in review report, clear explanation

**Scenario 7: Regression Test (CVE Enrichment)**

- Ticket: CVE-2024-1234 vulnerability enrichment
- Expected: CVE workflow works unchanged, no event investigation logic triggered
- Expected Duration: Same as before Epic 7 changes
- Validation: CVE enrichment and review complete successfully

### Success Criteria

**All Tests Must Pass:**

- ✅ Auto-detection logic correctly identifies ticket types (95% accuracy)
- ✅ Event investigation workflow completes end-to-end (AOD-4052 test)
- ✅ All 7 event checklists execute and score correctly
- ✅ Weighted scoring calculation accurate (manual verification)
- ✅ Disposition agreement/disagreement scenarios work correctly
- ✅ Fact verification returns accurate results from Perplexity MCP
- ✅ CVE workflows unchanged (regression tests pass)
- ✅ Performance targets met (investigation 10-15min, review 15-20min)

**Pass Criteria:** 100% of test scenarios pass with no critical defects

**Conditional Pass:** Minor defects identified but do not block story completion (defer to future stories)

**Fail:** Any critical defect that prevents core functionality from working

## Change Log

| Date       | Version | Description            | Author     |
| ---------- | ------- | ---------------------- | ---------- |
| 2025-11-09 | 1.0     | Initial story creation | Sarah (PO) |

## Dev Agent Record

_To be populated during development_

## QA Results

_To be populated during QA_
