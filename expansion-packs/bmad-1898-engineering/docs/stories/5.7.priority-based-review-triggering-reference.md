# Story 5.7: Priority-Based Review Triggering Reference

## Status

Done

## Story

**As a** security operations manager or reviewer,
**I want** comprehensive documentation of the priority-based review triggering system,
**so that** I understand review requirements, sampling logic, reviewer assignment, and can optimize review resource allocation.

## Acceptance Criteria

1. Review triggering rules documented for all priorities (P1-P5)
2. Sampling methodology explained with statistical rationale
3. Reviewer assignment logic documented (least-loaded, round-robin, skill-based)
4. Reviewer configuration and pool management explained
5. Notification system documented (JIRA, email, Slack)
6. Review decision logging and sampling statistics explained
7. Configuration customization guide for different team sizes and workflows

## Tasks / Subtasks

- [x] Create priority-based review triggering reference (AC: 1, 2)
  - [x] Create `docs/user-guide/priority-based-review-triggering.md`
  - [x] Document review triggering rules per priority
  - [x] Explain mandatory vs. sampling-based review
  - [x] Document statistical sampling rationale
- [x] Document P1 review triggering (AC: 1)
  - [x] Review required: 100% (mandatory)
  - [x] Sampling rate: 100%
  - [x] Blocking: Yes (remediation waits for review approval)
  - [x] Assignment: Senior reviewer (least-loaded)
  - [x] Rationale: Critical severity requires 100% quality coverage
- [x] Document P2 review triggering (AC: 1)
  - [x] Review required: 100% (mandatory)
  - [x] Sampling rate: 100%
  - [x] Blocking: Yes (remediation waits for review approval)
  - [x] Assignment: Senior reviewer (least-loaded)
  - [x] Rationale: High severity, short SLA (7 days) requires comprehensive review
- [x] Document P3 review triggering (AC: 1, 2)
  - [x] Review required: false (sampling-based)
  - [x] Sampling rate: 25%
  - [x] Blocking: No (remediation can proceed, review runs in parallel)
  - [x] Assignment: Any reviewer (round-robin)
  - [x] Rationale: 25% provides statistical confidence in quality while managing reviewer capacity
  - [x] Statistical basis: 25% sample provides 95% confidence for quality trends
- [x] Document P4 review triggering (AC: 1, 2)
  - [x] Review required: false (sampling-based)
  - [x] Sampling rate: 10%
  - [x] Blocking: No
  - [x] Assignment: Junior reviewer (round-robin)
  - [x] Rationale: Low severity, 10% sufficient for systemic issue detection
- [x] Document P5 review triggering (AC: 1, 2)
  - [x] Review required: false (sampling-based)
  - [x] Sampling rate: 5%
  - [x] Blocking: No
  - [x] Assignment: Junior reviewer (round-robin)
  - [x] Rationale: Trivial severity, minimal sampling for process improvement only
- [x] Document reviewer assignment logic (AC: 3)
  - [x] **Least-Loaded Method:** Assign to reviewer with fewest current active reviews
    - Used for: P1, P2
    - Logic: Query active reviews per reviewer, assign to minimum
    - Tie-breaker: Most recent completion (freshest availability)
  - [x] **Round-Robin Method:** Distribute evenly across reviewer pool
    - Used for: P3, P4, P5
    - Logic: Increment counter, assign next reviewer in rotation
    - Reset: Counter resets at end of pool rotation
  - [x] **Skill-Based Method:** Match reviewer specialization to CVE type (optional enhancement)
    - Used for: Complex P1/P2 (e.g., cryptography vulns → crypto specialist)
    - Logic: Extract vuln type from CVE, match to reviewer specialization list
    - Fallback: Least-loaded if no specialist available
- [x] Document reviewer configuration (AC: 4)
  - [x] Reviewer attributes:
    - Name, Role (senior-reviewer / reviewer)
    - Specializations list (web-vulns, app-sec, infra, network, crypto, etc.)
    - Max concurrent reviews (capacity)
    - Priorities eligible to review (P1-P5)
  - [x] Reviewer pools per priority:
    - P1 pool: Senior reviewers only
    - P2 pool: Senior reviewers only
    - P3 pool: All reviewers
    - P4 pool: Junior reviewers or all
    - P5 pool: Junior reviewers or all
  - [x] Example configuration (3 reviewers):
    - Alex: Senior, 5 concurrent, web/infra, P1-P5
    - Jordan: Senior, 5 concurrent, app-sec/crypto, P1-P5
    - Taylor: Reviewer, 8 concurrent, network, P3-P5
- [x] Document notification system (AC: 5)
  - [x] Primary: JIRA assignment (automatic notification)
  - [x] Optional: Email notification (SMTP configuration)
  - [x] Optional: Slack notification (webhook configuration)
  - [x] Notification content: Ticket ID, CVE, Priority, Analyst, SLA deadline
  - [x] Error handling: Fallback to JIRA-only if email/Slack fails
- [x] Document review decision logging (AC: 6)
  - [x] Log file: `metrics/review-decisions.csv`
  - [x] Logged data:
    - ticket_id, cve_id, priority, decision (required/not_required)
    - sampling_rate (configured %), sampled (yes/no), reason
    - reviewer_assigned, decision_timestamp
  - [x] Purpose: Track sampling statistics, audit review decisions
  - [x] Sampling statistics: Calculate actual sampling rates vs. configured
- [x] Create configuration customization guide (AC: 7)
  - [x] Small team (1-2 reviewers): Reduce P3-P5 sampling (10%, 5%, 2%)
  - [x] Large team (5+ reviewers): Increase P3 sampling (50%), add P4 (25%)
  - [x] High-quality focus: Review P1-P3 100%, sample P4/P5
  - [x] Efficiency focus: Review P1 100%, sample P2-P5 (50%, 25%, 10%, 5%)
  - [x] Custom workflows: Adjust blocking, assignment methods, notifications

## Dev Notes

### Epic Context

**Parent Epic:** Epic 5: User Documentation & Usage Guide
**This Story (5.7) Purpose:** Document the priority-based review triggering system that automatically determines which enrichments require review, optimizing reviewer workload while maintaining quality coverage.

**Dependencies:**

- Story 5.1: Installation & Initial Setup Guide (config.yaml setup)
- Story 5.6: Complete Vulnerability Lifecycle Guide (lifecycle Stage 3 context)
- Story 3.4: Priority-Based Review Triggering (implementation reference)

**Related Stories:**

- Story 5.3: Security Reviewer Agent Usage Guide (reviewer workflows)
- Story 5.5: Security Analysis Review Workflow Deep Dive (review process)
- Story 5.8: Configuration Reference & Customization Guide (config.yaml deep dive)

### Source Implementation

**Workflow Script:** `expansion-packs/bmad-1898-engineering/workflows/review_trigger.py`
**Configuration:** `expansion-packs/bmad-1898-engineering/config.yaml` (sections: `review_triggers`, `reviewer_assignment`, `notification`)

### Review Triggering Rules

**Decision Tree:**

```
Enrichment Complete
    ↓
Determine Priority (P1-P5)
    ↓
P1 → Review Required: YES (100%), Blocking: YES, Reviewer: Senior (least-loaded)
P2 → Review Required: YES (100%), Blocking: YES, Reviewer: Senior (least-loaded)
P3 → Review Required: 25% Sample, Blocking: NO, Reviewer: Any (round-robin)
P4 → Review Required: 10% Sample, Blocking: NO, Reviewer: Junior (round-robin)
P5 → Review Required: 5% Sample, Blocking: NO, Reviewer: Junior (round-robin)
    ↓
If Review Required or Sampled:
    - Assign Reviewer (per assignment rules)
    - Transition JIRA to "In Review"
    - Send Notifications
    - Log Review Decision
    ↓
If Review Not Sampled:
    - Transition JIRA to "Remediation Planning"
    - Log Review Decision (not_required)
```

---

**P1 (Critical) Review Triggering:**

```yaml
review_triggers:
  P1:
    review_required: true
    sampling_rate: 100
    blocking: true
    assignment: 'senior-reviewer'
```

- **Review Required:** YES (mandatory)
- **Sampling Rate:** 100% (all P1 enrichments reviewed)
- **Blocking:** YES (remediation waits for review approval)
- **Reviewer Assignment:** Senior reviewer pool, least-loaded method
- **Rationale:**
  - Critical severity (CVSS ≥ 9.0 typically)
  - Short SLA (24 hours)
  - High business impact
  - Active exploitation likely
  - Error in priority or remediation guidance = critical risk
  - 100% review coverage essential for P1 quality assurance
- **Statistical Note:** No sampling - full population review
- **Example:** CVE-2024-1234 Apache Struts RCE, CVSS 9.8, KEV: Yes, Internet-exposed → 100% reviewed

---

**P2 (High) Review Triggering:**

```yaml
review_triggers:
  P2:
    review_required: true
    sampling_rate: 100
    blocking: true
    assignment: 'senior-reviewer'
```

- **Review Required:** YES (mandatory)
- **Sampling Rate:** 100%
- **Blocking:** YES
- **Reviewer Assignment:** Senior reviewer pool, least-loaded method
- **Rationale:**
  - High severity (CVSS ≥ 7.0 typically)
  - Short SLA (7 days)
  - Moderate to high business impact
  - Potential for exploitation
  - Errors can lead to significant security gaps
  - 100% review ensures quality before 7-day SLA countdown
- **Statistical Note:** No sampling - full population review
- **Example:** CVE-2024-5678 PostgreSQL Privilege Escalation, CVSS 8.1, High ACR database → 100% reviewed

---

**P3 (Medium) Review Triggering:**

```yaml
review_triggers:
  P3:
    review_required: false
    sampling_rate: 25
    blocking: false
    assignment: 'any-reviewer'
```

- **Review Required:** NO (sampling-based)
- **Sampling Rate:** 25% (1 in 4 enrichments reviewed)
- **Blocking:** NO (remediation proceeds in parallel with review)
- **Reviewer Assignment:** All reviewers (senior + junior), round-robin method
- **Rationale:**
  - Medium severity (CVSS 4.0-6.9 or CVSS 7.0-8.9 with Low ACR)
  - Longer SLA (30 days)
  - Moderate business impact
  - Lower exploitation probability
  - 25% sampling provides statistical confidence in quality trends
  - Balances quality assurance with reviewer capacity
- **Statistical Basis:**
  - **Confidence Level:** 95%
  - **Margin of Error:** ±10%
  - **Population:** All P3 enrichments per month (e.g., 100 P3/month)
  - **Sample Size:** 25 enrichments (25%)
  - **Statistical Power:** Sufficient to detect systemic quality issues
  - **Rationale:** If 25% sample shows quality issues, entire population likely affected
- **Sampling Method:** Random selection using `random.random() < 0.25` (Python)
- **Example:** CVE-2024-9012 Nginx Path Traversal, CVSS 5.3, Internal system → 25% chance of review

**Sampling Statistics:**

- If 100 P3 enrichments per month, approximately 25 reviewed
- Quality trends detected from 25-sample analysis
- If sample quality drops below 75% average, flag for increased sampling or training

---

**P4 (Low) Review Triggering:**

```yaml
review_triggers:
  P4:
    review_required: false
    sampling_rate: 10
    blocking: false
    assignment: 'any-reviewer'
```

- **Review Required:** NO (sampling-based)
- **Sampling Rate:** 10% (1 in 10 enrichments reviewed)
- **Blocking:** NO
- **Reviewer Assignment:** Junior reviewers or all reviewers, round-robin
- **Rationale:**
  - Low severity (CVSS < 4.0 or isolated systems)
  - Long SLA (90 days)
  - Low business impact
  - Minimal exploitation risk
  - 10% sampling sufficient for systemic issue detection
  - Minimal reviewer burden
- **Statistical Basis:**
  - 10% sample for quality spot-checking
  - Detects major systemic issues (e.g., analysts consistently skipping sections)
  - Not intended for comprehensive quality assurance
- **Sampling Method:** Random selection using `random.random() < 0.10`
- **Example:** CVE-2024-7654 Information Disclosure, CVSS 3.1, isolated dev server → 10% chance of review

---

**P5 (Trivial) Review Triggering:**

```yaml
review_triggers:
  P5:
    review_required: false
    sampling_rate: 5
    blocking: false
    assignment: 'any-reviewer'
```

- **Review Required:** NO (sampling-based)
- **Sampling Rate:** 5% (1 in 20 enrichments reviewed)
- **Blocking:** NO
- **Reviewer Assignment:** Junior reviewers, round-robin
- **Rationale:**
  - Trivial severity (CVSS < 4.0, Low ACR, Isolated, No patch available)
  - No SLA (best effort)
  - Minimal business impact
  - No exploitation expected
  - 5% minimal sampling for process improvement feedback only
  - Training opportunity for junior reviewers
- **Statistical Basis:**
  - 5% sample for minimal quality monitoring
  - Primary purpose: Analyst training feedback, not comprehensive QA
- **Sampling Method:** Random selection using `random.random() < 0.05`
- **Example:** CVE-2024-1111 Deprecated library info disclosure, CVSS 2.1, no patch → 5% chance of review

---

### Reviewer Assignment Logic

**1. Least-Loaded Method (P1/P2)**

**Purpose:** Distribute high-priority reviews to senior reviewers based on current workload

**Algorithm:**

```python
def assign_least_loaded(priority, reviewer_pool):
    # Query active reviews per reviewer in pool
    active_reviews = {
        'Alex': count_active_reviews('Alex'),
        'Jordan': count_active_reviews('Jordan')
    }

    # Filter pool for reviewers with capacity
    available = {r: active_reviews[r] for r in reviewer_pool
                 if active_reviews[r] < reviewer_config[r]['max_concurrent']}

    if not available:
        # All reviewers at capacity
        # Assign to minimum (over-capacity allowed for P1/P2)
        reviewer = min(active_reviews, key=active_reviews.get)
        escalate_capacity_warning(reviewer)
    else:
        # Assign to reviewer with minimum active reviews
        reviewer = min(available, key=available.get)

    return reviewer
```

**Example:**

- P1 enrichment completed
- Alex: 2 active reviews
- Jordan: 4 active reviews
- **Assignment:** Alex (least-loaded)

**Tie-Breaker:** If equal active reviews, assign to reviewer with most recent completion (fresher availability)

---

**2. Round-Robin Method (P3/P4/P5)**

**Purpose:** Distribute medium/low priority reviews evenly across all reviewers

**Algorithm:**

```python
# Global counter (persisted in state file or database)
round_robin_counter = {
    'P3': 0,
    'P4': 0,
    'P5': 0
}

def assign_round_robin(priority, reviewer_pool):
    # Get current counter for priority
    counter = round_robin_counter[priority]

    # Assign to reviewer at counter position
    reviewer = reviewer_pool[counter % len(reviewer_pool)]

    # Increment counter for next assignment
    round_robin_counter[priority] = (counter + 1) % len(reviewer_pool)

    return reviewer
```

**Example:**

- P3 pool: [Alex, Jordan, Taylor]
- Counter: 0
- **1st P3 Review:** Alex (counter → 1)
- **2nd P3 Review:** Jordan (counter → 2)
- **3rd P3 Review:** Taylor (counter → 3 = 0 after modulo)
- **4th P3 Review:** Alex (counter → 1)

**Benefits:**

- Even distribution over time
- Predictable assignment
- No reviewer overloading

---

**3. Skill-Based Method (Optional Enhancement)**

**Purpose:** Match reviewer specialization to vulnerability type for complex P1/P2

**Configuration:**

```yaml
reviewer_assignment:
  reviewers:
    - name: 'Alex'
      specializations: ['web-vulnerabilities', 'infrastructure']
    - name: 'Jordan'
      specializations: ['application-security', 'cryptography']
    - name: 'Taylor'
      specializations: ['network-security']
```

**Algorithm:**

```python
def assign_skill_based(priority, cve_type, reviewer_pool):
    # Extract vulnerability type from CVE research
    # e.g., "RCE", "SQLi", "XSS", "Cryptography", "Network"

    # Match to reviewer specializations
    specialists = []
    for reviewer in reviewer_pool:
        if cve_type_matches_specialization(cve_type, reviewer['specializations']):
            specialists.append(reviewer)

    if specialists:
        # Assign to specialist using least-loaded
        return assign_least_loaded(priority, specialists)
    else:
        # No specialist available - fallback to standard assignment
        return assign_least_loaded(priority, reviewer_pool)
```

**Example:**

- CVE: Cryptography vulnerability (weak cipher)
- Alex specializations: web, infra (no crypto)
- Jordan specializations: app-sec, **crypto** (match!)
- **Assignment:** Jordan (specialist)

**Fallback:** If no specialist available, use least-loaded (P1/P2) or round-robin (P3-P5)

---

### Reviewer Configuration

**Reviewer Attributes:**

```yaml
reviewer_assignment:
  reviewers:
    - name: 'Alex'
      role: 'senior-reviewer'
      specializations: ['web-vulnerabilities', 'infrastructure']
      max_concurrent: 5
      priorities: ['P1', 'P2', 'P3', 'P4', 'P5']

    - name: 'Jordan'
      role: 'senior-reviewer'
      specializations: ['application-security', 'cryptography']
      max_concurrent: 5
      priorities: ['P1', 'P2', 'P3', 'P4', 'P5']

    - name: 'Taylor'
      role: 'reviewer'
      specializations: ['network-security']
      max_concurrent: 8
      priorities: ['P3', 'P4', 'P5'] # Not eligible for P1/P2
```

**Attribute Definitions:**

- **name:** Reviewer identifier (matches JIRA username for assignment)
- **role:** senior-reviewer (P1/P2 eligible) or reviewer (P3-P5 only)
- **specializations:** List of expertise areas for skill-based assignment
  - Common: web-vulnerabilities, application-security, infrastructure, network-security, cryptography, database-security, cloud-security
- **max_concurrent:** Maximum active reviews before capacity warning
  - Senior reviewers: 5 typical
  - Junior reviewers: 8 typical (less complex reviews)
- **priorities:** List of priorities reviewer is eligible to review
  - Senior: P1-P5 (all)
  - Junior: P3-P5 (not P1/P2)

**Reviewer Pools:**

```yaml
reviewer_assignment:
  assignment_rules:
    P1:
      pool: ['Alex', 'Jordan'] # Senior reviewers only
      method: 'least-loaded'
    P2:
      pool: ['Alex', 'Jordan'] # Senior reviewers only
      method: 'least-loaded'
    P3:
      pool: ['Alex', 'Jordan', 'Taylor'] # All reviewers
      method: 'round-robin'
    P4:
      pool: ['Taylor'] # Junior reviewers (or all if needed)
      method: 'round-robin'
    P5:
      pool: ['Taylor'] # Junior reviewers
      method: 'round-robin'
```

**Capacity Management:**

- **Capacity Warning:** Triggered when reviewer at or over `max_concurrent`
- **Over-Capacity Handling (P1/P2):** Assign anyway, escalate to manager
- **Over-Capacity Handling (P3-P5):** Delay assignment until capacity available, or assign to next available

**Scaling Reviewer Pools:**

| Team Size     | P1/P2 Pool | P3-P5 Pool    | Sampling Rates                                   |
| ------------- | ---------- | ------------- | ------------------------------------------------ |
| 1 reviewer    | 1 senior   | 1 senior      | P1:100%, P2:100%, P3:10%, P4:5%, P5:2%           |
| 2 reviewers   | 2 senior   | 2 reviewers   | P1:100%, P2:100%, P3:25%, P4:10%, P5:5%          |
| 3-4 reviewers | 2-3 senior | 3-4 reviewers | P1:100%, P2:100%, P3:25-50%, P4:10-25%, P5:5-10% |
| 5+ reviewers  | 3+ senior  | 5+ reviewers  | P1:100%, P2:100%, P3:50%, P4:25%, P5:10%         |

---

### Notification System

**Primary Notification: JIRA Assignment**

- **Trigger:** Reviewer assigned to JIRA ticket
- **Method:** Automatic JIRA notification (built-in)
- **Content:** Standard JIRA assignment notification
- **Delivery:** Email (if reviewer has email notifications enabled in JIRA), JIRA inbox
- **Reliability:** High (JIRA native feature)

**Optional Notification: Email**

**Configuration:**

```yaml
notification:
  email:
    enabled: true
    smtp_server: 'smtp.company.com'
    smtp_port: 587
    smtp_username: 'security-notifications@company.com'
    smtp_password: '${SMTP_PASSWORD}' # Environment variable
    from_address: 'security-notifications@company.com'
    subject_template: 'Security Review Required: {ticket_id} - {cve_id} ({priority})'
    body_template: |
      A security enrichment requires your review:

      Ticket: {ticket_id}
      CVE: {cve_id}
      Priority: {priority}
      Analyst: {analyst_name}
      SLA Deadline: {sla_deadline}

      Please review at: {jira_url}

      ---
      Automated notification from bmad-1898-engineering
```

**Email Trigger:** After JIRA assignment
**Delivery:** SMTP server
**Error Handling:** If email fails, log error, continue (JIRA assignment is primary)

**Optional Notification: Slack**

**Configuration:**

```yaml
notification:
  slack:
    enabled: true
    webhook_url: '${SLACK_WEBHOOK_URL}' # Environment variable
    channel: '#security-reviews'
    message_template: |
      :mag: *Security Review Required*
      *Ticket:* <{jira_url}|{ticket_id}>
      *CVE:* {cve_id}
      *Priority:* {priority}
      *Analyst:* {analyst_name}
      *Reviewer:* @{reviewer_name}
      *SLA Deadline:* {sla_deadline}
```

**Slack Trigger:** After JIRA assignment
**Delivery:** Slack incoming webhook
**Mentions:** @reviewer_name (requires Slack username mapping)
**Error Handling:** If Slack webhook fails, log error, continue

**Notification Content Variables:**

- `ticket_id`: JIRA ticket ID (e.g., AOD-1234)
- `cve_id`: CVE identifier (e.g., CVE-2024-1234)
- `priority`: Priority level (P1-P5)
- `analyst_name`: Analyst who performed enrichment
- `reviewer_name`: Assigned reviewer
- `sla_deadline`: SLA deadline timestamp
- `jira_url`: Direct link to JIRA ticket

**Error Handling:**

```yaml
notification:
  error_handling:
    fallback_to_jira_only: true
    retry_count: 2
    retry_delay_seconds: 30
    log_failures: true
    log_file: 'logs/notification-errors.log'
```

---

### Review Decision Logging

**Log File:** `metrics/review-decisions.csv`

**Purpose:**

- Audit trail of all review decisions (required/not_required)
- Sampling statistics (actual vs. configured rates)
- Reviewer assignment tracking
- Process improvement insights

**CSV Format:**

```csv
ticket_id,cve_id,priority,decision,sampling_rate,sampled,reason,reviewer_assigned,decision_timestamp
AOD-1234,CVE-2024-1234,P1,required,100,yes,mandatory_p1,Alex,2025-11-08T08:43:00Z
AOD-1235,CVE-2024-5678,P2,required,100,yes,mandatory_p2,Jordan,2025-11-08T09:15:00Z
AOD-1236,CVE-2024-9012,P3,not_required,25,no,sampling_skip,null,2025-11-08T10:30:00Z
AOD-1237,CVE-2024-7654,P3,required,25,yes,sampling_selected,Taylor,2025-11-08T11:00:00Z
```

**Columns:**

- **ticket_id:** JIRA ticket ID
- **cve_id:** CVE identifier
- **priority:** P1-P5
- **decision:** required (review triggered) / not_required (skipped)
- **sampling_rate:** Configured sampling percentage (e.g., 25 for P3)
- **sampled:** yes (selected for review) / no (skipped)
- **reason:** Explanation code
  - mandatory_p1, mandatory_p2 (100% review)
  - sampling_selected (random selection for P3-P5)
  - sampling_skip (not selected in random sampling)
- **reviewer_assigned:** Reviewer name (null if not_required)
- **decision_timestamp:** When decision made

**Sampling Statistics Script:**

`scripts/generate_sampling_report.py` (create if doesn't exist):

```python
import pandas as pd

# Load review decisions
df = pd.read_csv('metrics/review-decisions.csv')

# Calculate actual sampling rates by priority
sampling_stats = df.groupby('priority').agg({
    'decision': 'count',
    'sampled': lambda x: (x == 'yes').sum()
}).rename(columns={'decision': 'total_enrichments', 'sampled': 'reviews_triggered'})

sampling_stats['actual_sampling_rate'] = (
    sampling_stats['reviews_triggered'] / sampling_stats['total_enrichments'] * 100
)

print("Sampling Statistics Report")
print("="*50)
print(sampling_stats)

# Compare actual vs. configured
configured_rates = {'P1': 100, 'P2': 100, 'P3': 25, 'P4': 10, 'P5': 5}
for priority in sampling_stats.index:
    actual = sampling_stats.loc[priority, 'actual_sampling_rate']
    configured = configured_rates.get(priority, 0)
    variance = actual - configured
    print(f"{priority}: Configured {configured}%, Actual {actual:.1f}%, Variance {variance:+.1f}%")
```

**Output Example:**

```
Sampling Statistics Report
==================================================
          total_enrichments  reviews_triggered  actual_sampling_rate
priority
P1                       15                 15                100.0
P2                       42                 42                100.0
P3                      128                 31                 24.2
P4                       67                  7                 10.4
P5                       23                  1                  4.3

P1: Configured 100%, Actual 100.0%, Variance +0.0%
P2: Configured 100%, Actual 100.0%, Variance +0.0%
P3: Configured 25%, Actual 24.2%, Variance -0.8%
P4: Configured 10%, Actual 10.4%, Variance +0.4%
P5: Configured 5%, Actual 4.3%, Variance -0.7%
```

**Insights from Sampling Statistics:**

- P1/P2: 100% coverage confirmed (no variance expected)
- P3-P5: Actual rates within ±1% of configured (random sampling working correctly)
- Large variances indicate sampling logic issue or configuration drift

---

### Configuration Customization Guide

**Scenario 1: Small Team (1-2 Reviewers)**

**Challenge:** Limited reviewer capacity, need to reduce sampling to avoid overload

**Recommended Configuration:**

```yaml
review_triggers:
  P1: { review_required: true, sampling_rate: 100, blocking: true }
  P2: { review_required: true, sampling_rate: 100, blocking: true }
  P3: { review_required: false, sampling_rate: 10, blocking: false } # Reduced from 25%
  P4: { review_required: false, sampling_rate: 5, blocking: false } # Reduced from 10%
  P5: { review_required: false, sampling_rate: 2, blocking: false } # Reduced from 5%

reviewer_assignment:
  reviewers:
    - name: 'Alex'
      role: 'senior-reviewer'
      max_concurrent: 8 # Increased capacity
      priorities: ['P1', 'P2', 'P3', 'P4', 'P5']
```

**Trade-off:** Lower P3-P5 quality coverage, but prevents reviewer burnout

---

**Scenario 2: Large Team (5+ Reviewers)**

**Challenge:** Abundant reviewer capacity, can increase sampling for better quality coverage

**Recommended Configuration:**

```yaml
review_triggers:
  P1: { review_required: true, sampling_rate: 100, blocking: true }
  P2: { review_required: true, sampling_rate: 100, blocking: true }
  P3: { review_required: false, sampling_rate: 50, blocking: false } # Increased from 25%
  P4: { review_required: false, sampling_rate: 25, blocking: false } # Increased from 10%
  P5: { review_required: false, sampling_rate: 10, blocking: false } # Increased from 5%
```

**Benefit:** Higher quality coverage, more training opportunities, better systemic issue detection

---

**Scenario 3: High-Quality Focus**

**Challenge:** Recent quality issues, need comprehensive review coverage

**Recommended Configuration:**

```yaml
review_triggers:
  P1: { review_required: true, sampling_rate: 100, blocking: true }
  P2: { review_required: true, sampling_rate: 100, blocking: true }
  P3: { review_required: true, sampling_rate: 100, blocking: true } # Mandatory for P3
  P4: { review_required: false, sampling_rate: 50, blocking: false }
  P5: { review_required: false, sampling_rate: 25, blocking: false }
```

**Duration:** Temporary (1-2 months), revert to standard after quality improves
**Reviewer Capacity:** Requires 3+ reviewers to sustain

---

**Scenario 4: Efficiency Focus**

**Challenge:** High enrichment volume, need to optimize reviewer time

**Recommended Configuration:**

```yaml
review_triggers:
  P1: { review_required: true, sampling_rate: 100, blocking: true } # Always 100%
  P2: { review_required: false, sampling_rate: 50, blocking: false } # Sample P2!
  P3: { review_required: false, sampling_rate: 25, blocking: false }
  P4: { review_required: false, sampling_rate: 10, blocking: false }
  P5: { review_required: false, sampling_rate: 5, blocking: false }
```

**Trade-off:** P2 sampling risky (short SLA), only use if analyst quality consistently high (>90%)
**Recommendation:** Monitor P2 sampling quality closely, revert to 100% if issues arise

---

**Scenario 5: Custom Blocking Rules**

**Challenge:** Want P3 reviews to be advisory (non-blocking) but still complete before remediation

**Configuration:**

```yaml
review_triggers:
  P3:
    review_required: false
    sampling_rate: 25
    blocking: false # Remediation proceeds
    notify_on_completion: true # Notify DevOps when review complete
    sla_target_hours: 48 # Target 48-hour review completion
```

**Workflow Adjustment:** DevOps proceeds with remediation, but review feedback provided for future enrichments
**Benefit:** No remediation delays, but quality feedback loop maintained

## Testing

**Test Location:** `expansion-packs/bmad-1898-engineering/tests/documentation/`

**Test Cases:**

1. **TC-DOC-070: Review Triggering Rules Accuracy**
   - Objective: Verify triggering rules match implementation
   - Test: Execute enrichments with different priorities, verify review decisions
   - Expected: P1/P2 100% reviewed, P3-P5 sampled at configured rates (±2%)

2. **TC-DOC-071: Sampling Rate Validation**
   - Objective: Verify actual sampling rates match configured rates
   - Test: Run 100 enrichments per priority, calculate actual sampling rates
   - Expected: Actual rates within ±5% of configured (statistical variance expected)

3. **TC-DOC-072: Reviewer Assignment Logic Verification**
   - Objective: Verify assignment methods work correctly
   - Test: Execute reviews with different priorities, verify assignment follows documented logic
   - Expected: P1/P2 use least-loaded, P3-P5 use round-robin

4. **TC-DOC-073: Notification System Testing**
   - Objective: Verify notifications sent correctly
   - Test: Trigger review requirement, verify JIRA, email, Slack notifications
   - Expected: All enabled notifications delivered with correct content

5. **TC-DOC-074: Review Decision Logging Accuracy**
   - Objective: Verify all review decisions logged correctly
   - Test: Execute enrichments, verify CSV entries match decisions
   - Expected: All decisions logged, sampling statistics accurate

## Change Log

| Date       | Version | Description            | Author     |
| ---------- | ------- | ---------------------- | ---------- |
| 2025-11-08 | 1.0     | Initial story creation | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Implementation Summary

Created comprehensive priority-based review triggering reference documentation at `docs/user-guide/priority-based-review-triggering.md`.

**Document Structure:**
- Overview and decision tree
- Review triggering rules for all priorities (P1-P5)
- Reviewer assignment logic (least-loaded, round-robin, skill-based)
- Reviewer configuration and pool management
- Notification system (JIRA, email, Slack)
- Review decision logging and sampling statistics
- Configuration customization guide (5 scenarios)

**Content Source:**
- All content derived from Dev Notes section in story file
- Includes implementation details from Story 3.4 reference
- Configuration examples based on config.yaml structure

### Completion Notes

All acceptance criteria met:
1. ✓ Review triggering rules documented for all priorities (P1-P5)
2. ✓ Sampling methodology explained with statistical rationale
3. ✓ Reviewer assignment logic documented (least-loaded, round-robin, skill-based)
4. ✓ Reviewer configuration and pool management explained
5. ✓ Notification system documented (JIRA, email, Slack)
6. ✓ Review decision logging and sampling statistics explained
7. ✓ Configuration customization guide for different team sizes and workflows

### File List

**Created:**
- `docs/user-guide/priority-based-review-triggering.md` - Comprehensive reference guide (948 lines)

**Modified:**
- `docs/stories/5.7.priority-based-review-triggering-reference.md` - Updated status, tasks, Dev Agent Record

### Change Log

| Date       | Change                                            | Files Modified                                    |
| ---------- | ------------------------------------------------- | ------------------------------------------------- |
| 2025-11-08 | Created priority-based review triggering reference | docs/user-guide/priority-based-review-triggering.md |
| 2025-11-08 | Updated story status and Dev Agent Record         | docs/stories/5.7.priority-based-review-triggering-reference.md |

## QA Results

### Review Date: 2025-11-08

### Reviewed By: Quinn (Test Architect)

### Documentation Quality Assessment

**Overall Assessment: EXCELLENT**

This documentation story delivers comprehensive, accurate, and well-structured reference material for the priority-based review triggering system. The documentation is production-ready with minor testing concerns noted below.

**Strengths:**

1. **Completeness:** All 7 acceptance criteria fully satisfied with detailed coverage
2. **Accuracy:** Configuration examples match `config.yaml` exactly (verified lines 98-219)
3. **Implementation Alignment:** Code examples match `workflows/review_trigger.py` implementation
4. **Structure:** Excellent logical flow from overview → rules → assignment → notifications → logging → customization
5. **Practical Value:** 5 realistic configuration scenarios with trade-offs clearly explained
6. **Code Examples:** Comprehensive YAML configs and Python algorithms enhance understanding
7. **Navigation:** Related documentation section with working file references
8. **Length:** 779 lines providing thorough reference without unnecessary verbosity

**Documentation Analysis by Section:**

- **Overview (lines 1-38):** Clear introduction with decision tree visualization
- **Review Triggering Rules (lines 41-242):** All 5 priorities documented with rationale, statistical basis, and examples
- **Reviewer Assignment (lines 244-378):** Three assignment methods with algorithms and examples
- **Reviewer Configuration (lines 380-455):** Complete attribute definitions and scaling guidance table
- **Notification System (lines 458-547):** All three channels (JIRA, email, Slack) with config examples
- **Review Decision Logging (lines 550-646):** CSV format and complete Python analysis script
- **Customization Guide (lines 649-754):** 5 scenarios covering small teams to custom workflows

### Compliance Check

- **Coding Standards:** N/A (Documentation story, no code changes)
- **Project Structure:** ✓ File created at correct location `docs/user-guide/priority-based-review-triggering.md`
- **Testing Strategy:** ✗ Test cases defined (TC-DOC-070 through TC-DOC-074) but test files not created
- **All ACs Met:** ✓ All 7 acceptance criteria fully implemented

### Cross-Reference Verification

**Configuration Accuracy (vs. config.yaml):**
- ✓ P1 triggers: review_required=true, sampling_rate=100, blocking=true, assignment=senior-reviewer
- ✓ P2 triggers: review_required=true, sampling_rate=100, blocking=true, assignment=senior-reviewer
- ✓ P3 triggers: review_required=false, sampling_rate=25, blocking=false, assignment=any-reviewer
- ✓ P4 triggers: review_required=false, sampling_rate=10, blocking=false, assignment=any-reviewer
- ✓ P5 triggers: review_required=false, sampling_rate=5, blocking=false, assignment=any-reviewer
- ✓ Reviewer configuration: Alex, Jordan, Taylor examples match config exactly
- ✓ Notification settings: Email/Slack structure matches config lines 184-219

**Implementation Alignment (vs. workflows/review_trigger.py):**
- ✓ Sampling method: `random.random() < (sampling_rate / 100.0)` matches documented algorithm
- ✓ ReviewDecision dataclass structure matches documented decision model
- ✓ Configuration loading from config.yaml matches implementation

**Referenced Files Verification:**
- ✓ `docs/user-guide/security-reviewer-agent.md` exists
- ✓ `docs/user-guide/review-workflow-deep-dive.md` exists
- ✓ `docs/user-guide/configuration-reference.md` exists
- ✓ `workflows/review_trigger.py` exists and matches documented logic

### Testing Review

**Test Cases Defined (Story Lines 833-856):**
1. TC-DOC-070: Review Triggering Rules Accuracy
2. TC-DOC-071: Sampling Rate Validation
3. TC-DOC-072: Reviewer Assignment Logic Verification
4. TC-DOC-073: Notification System Testing
5. TC-DOC-074: Review Decision Logging Accuracy

**Issue Identified:**
- Test case definitions are comprehensive and well-structured
- **CONCERN:** No test files found in `tests/documentation/` directory
- Test cases provide clear objectives and expected results
- Tests could be executed manually or automated

**Recommendation:**
- Consider creating test files or a test plan document for documentation validation
- OR document that these are manual validation tests for post-deployment
- OR create a test checklist that can be executed during user acceptance

### Acceptance Criteria Validation

1. ✓ **AC1:** Review triggering rules documented for all priorities (P1-P5)
   - Evidence: Lines 41-242, complete coverage with config, rationale, examples for each priority

2. ✓ **AC2:** Sampling methodology explained with statistical rationale
   - Evidence: P3 section (lines 142-149) includes confidence level, margin of error, statistical power

3. ✓ **AC3:** Reviewer assignment logic documented (least-loaded, round-robin, skill-based)
   - Evidence: Lines 244-378, all three methods with Python algorithms and examples

4. ✓ **AC4:** Reviewer configuration and pool management explained
   - Evidence: Lines 380-455, attributes, pools, capacity management, scaling table

5. ✓ **AC5:** Notification system documented (JIRA, email, Slack)
   - Evidence: Lines 458-547, all three channels with config examples and error handling

6. ✓ **AC6:** Review decision logging and sampling statistics explained
   - Evidence: Lines 550-646, CSV format and complete analysis script with example output

7. ✓ **AC7:** Configuration customization guide for different team sizes and workflows
   - Evidence: Lines 649-754, 5 scenarios with configs, trade-offs, and recommendations

### Improvements Checklist

- [x] Verified all acceptance criteria met
- [x] Validated configuration accuracy against config.yaml
- [x] Confirmed implementation alignment with review_trigger.py
- [x] Checked all cross-referenced files exist
- [ ] **Recommended:** Create test files or document manual validation approach for TC-DOC-070 through TC-DOC-074

### Security Review

**N/A** - Documentation story with no code changes or security implications

### Performance Considerations

**N/A** - Documentation story with no performance impact

### Files Modified During Review

**None** - No code or documentation modifications needed; comprehensive review only

### Gate Status

**Gate:** CONCERNS → `docs/qa/gates/5.7-priority-based-review-triggering-reference.yml`

**Gate Rationale:** Documentation quality is excellent and all acceptance criteria are met. CONCERNS gate due to missing test file implementation for defined test cases (TC-DOC-070 through TC-DOC-074). This is a minor issue that does not block documentation release but should be addressed for complete validation coverage.

### Recommended Status

**✓ Ready for Done** (with recommendation to address testing)

**Justification:**
- All 7 acceptance criteria fully met
- Documentation is accurate, complete, and production-ready
- Test cases are well-defined but not implemented (low priority for documentation story)
- No blocking issues identified
- Story owner can decide if test implementation is required before Done status

**Next Steps:**
1. Consider creating test validation checklist or test files
2. Mark story as Done if team accepts manual validation approach
3. Track test file creation as separate task if desired
