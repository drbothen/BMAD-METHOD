# Story 3.2: Security Analysis Review Workflow

## Status

Ready for Review

## Story

**As a** security operations team,
**I want** a systematic peer review workflow,
**so that** quality assurance is thorough and consistent.

## Acceptance Criteria

1. Workflow includes all 7 stages: Preparation â†’ Evaluation â†’ Gap Identification â†’ Bias Detection â†’ (Optional) Fact Verification â†’ Documentation â†’ Feedback Loop
2. 90% of workflow executions complete within 15-20 minutes
3. Review report posted as JIRA comment with all required sections (Review Metadata, Executive Summary, Strengths, Quality Scores, Critical/Significant/Minor Issues, Bias Assessment, Fact Verification, Recommendations, Learning Resources, Next Steps)
4. When Critical Issues found, ticket status changes to "Needs Revision" and analyst is notified

## Tasks / Subtasks

- [ ] Verify MCP prerequisites (AC: 1, 3, 4)
  - [ ] Verify Atlassian MCP is configured and accessible
  - [ ] Test JIRA ticket read operation
  - [ ] Test JIRA comment posting operation
  - [ ] Check Perplexity MCP availability (optional for fact verification)
  - [ ] Document graceful degradation if Perplexity unavailable
- [ ] Create review workflow definition (AC: 1, 2)
  - [ ] Create `workflows/security-analysis-review-workflow.yaml`
  - [ ] Define all 7 workflow stages
  - [ ] Specify inputs/outputs for each stage
  - [ ] Add Mermaid diagram
  - [ ] Include time estimates per stage
  - [ ] Add error handling for missing MCP services
- [ ] Define Stage 1: Preparation (AC: 1)
  - [ ] Input: JIRA ticket ID with enrichment
  - [ ] Actions: Read ticket, read enrichment comment, extract claims
  - [ ] Output: Enrichment to review, claims list
  - [ ] Time: 2-3 minutes
- [ ] Define Stage 2: Systematic Evaluation (AC: 1)
  - [ ] Input: Enrichment document
  - [ ] Actions: Run 8 quality dimension checklists
  - [ ] Output: Quality scores per dimension, overall score
  - [ ] Time: 5-7 minutes
- [ ] Define Stage 3: Gap Identification (AC: 1)
  - [ ] Input: Checklist results
  - [ ] Actions: Categorize gaps as Critical/Significant/Minor
  - [ ] Output: Structured findings with recommendations
  - [ ] Time: 3-4 minutes
- [ ] Define Stage 4: Cognitive Bias Detection (AC: 1)
  - [ ] Input: Enrichment document
  - [ ] Actions: Run cognitive bias checklist
  - [ ] Output: Detected biases with debiasing strategies
  - [ ] Time: 2-3 minutes
- [ ] Define Stage 5: Fact Verification (Optional) (AC: 1)
  - [ ] Input: Critical claims (CVSS, KEV, etc.)
  - [ ] Actions: Verify against authoritative sources via Perplexity
  - [ ] Output: Accuracy score, discrepancies
  - [ ] Time: 3-5 minutes (if performed)
- [ ] Define Stage 6: Review Documentation (AC: 1, 3)
  - [ ] Input: All review findings
  - [ ] Actions: Generate review report using template
  - [ ] Output: Constructive review report
  - [ ] Time: 2-3 minutes
- [ ] Define Stage 7: Feedback Loop (AC: 1, 4)
  - [ ] Input: Review report
  - [ ] Actions: Post review to JIRA, assign back to analyst
  - [ ] Output: Review comment in JIRA, analyst notified
  - [ ] Time: 1 minute
- [ ] Create workflow orchestration task file structure (AC: 2, 3, 4)
  - [ ] Create `tasks/review-security-enrichment.md`
  - [ ] Define task purpose and usage
  - [ ] Document task parameters (ticket ID, optional skip fact verification)
- [ ] Implement workflow stage execution logic (AC: 1, 2)
  - [ ] Implement Stage 1-7 sequential execution
  - [ ] Add progress tracking UI (stage status indicators)
  - [ ] Implement time tracking per stage
  - [ ] Add total execution time validation (target: 15-20 min)
- [ ] Implement error handling and resilience (AC: 1)
  - [ ] Handle Atlassian MCP unavailable (halt with clear message)
  - [ ] Handle Perplexity MCP unavailable (skip fact verification gracefully)
  - [ ] Handle JIRA ticket not found (prompt user to verify ticket ID)
  - [ ] Add retry logic for transient failures
- [ ] Implement JIRA integration and notifications (AC: 3, 4)
  - [ ] Post review report as JIRA comment
  - [ ] Update ticket status to "Needs Revision" if Critical Issues found
  - [ ] Assign ticket back to original analyst
  - [ ] Save review report to local directory
  - [ ] Verify JIRA operations successful

## Dev Notes

### Workflow YAML Structure

```yaml
workflow:
  id: security-analysis-review-v1
  name: Security Analysis Review Workflow
  version: 1.0
  description: Systematic peer review workflow for security enrichments
  estimated_duration: 15-20 minutes
  prerequisites:
    - JIRA ticket with analyst enrichment
    - Security Reviewer agent activated
    - Atlassian MCP configured
    - (Optional) Perplexity MCP for fact verification

  stages:
    - id: stage1-preparation
      name: Review Preparation
      duration: 2-3 minutes
      inputs:
        - JIRA ticket ID
      actions:
        - Read JIRA ticket via Atlassian MCP
        - Extract analyst enrichment comment
        - Parse enrichment structure
        - Extract factual claims for verification
      outputs:
        - Enrichment document
        - Claims list (CVSS, EPSS, KEV, etc.)
        - Analyst name
      success_criteria:
        - Enrichment successfully extracted
        - Claims identified

    - id: stage2-evaluation
      name: Systematic Quality Evaluation
      duration: 5-7 minutes
      inputs:
        - Enrichment document
      actions:
        - Execute technical-accuracy-checklist.md
        - Execute completeness-checklist.md
        - Execute actionability-checklist.md
        - Execute contextualization-checklist.md
        - Execute documentation-quality-checklist.md
        - Execute attack-mapping-validation-checklist.md
        - Execute cognitive-bias-checklist.md
        - Execute source-citation-checklist.md
        - Calculate scores per dimension
        - Calculate overall quality score
      outputs:
        - 8 dimension scores (percentages)
        - Overall quality score
        - Quality classification (Excellent/Good/Needs Improvement/Inadequate)
      success_criteria:
        - All 8 checklists executed
        - Overall score calculated

    - id: stage3-gap-identification
      name: Gap Identification & Categorization
      duration: 3-4 minutes
      inputs:
        - Checklist results
        - Failed checklist items
      actions:
        - Categorize each gap as Critical/Significant/Minor
        - Specify location for each gap
        - Explain impact of each gap
        - Provide recommended fixes
        - Link to learning resources
      outputs:
        - Critical issues list
        - Significant gaps list
        - Minor improvements list
      success_criteria:
        - All gaps categorized
        - Recommendations provided

    - id: stage4-bias-detection
      name: Cognitive Bias Detection
      duration: 2-3 minutes
      inputs:
        - Enrichment document
      actions:
        - Check for confirmation bias
        - Check for anchoring bias
        - Check for availability heuristic
        - Check for overconfidence bias
        - Check for recency bias
        - Provide specific examples
        - Suggest debiasing strategies
      outputs:
        - Detected biases with examples
        - Debiasing recommendations
      success_criteria:
        - Bias assessment complete
        - Constructive feedback provided

    - id: stage5-fact-verification
      name: Fact Verification (Optional)
      duration: 3-5 minutes
      optional: true
      inputs:
        - Claims list (CVSS, EPSS, KEV, patches)
      actions:
        - Verify CVSS score against NVD
        - Verify EPSS score against FIRST
        - Verify KEV status against CISA
        - Verify patch versions against vendor
        - Compare analyst claims with authoritative data
        - Document discrepancies
      outputs:
        - Accuracy score (% correct)
        - Discrepancies list with corrections
      success_criteria:
        - Critical claims verified
        - Discrepancies documented

    - id: stage6-documentation
      name: Review Report Documentation
      duration: 2-3 minutes
      inputs:
        - Quality scores
        - Gap findings
        - Bias detection results
        - Fact verification results (if performed)
      actions:
        - Use security-review-report-tmpl.yaml
        - Acknowledge strengths first
        - Document findings constructively
        - Provide prioritized recommendations
        - Link learning resources
        - Maintain blameless tone
      outputs:
        - Constructive review report (markdown)
      success_criteria:
        - All sections populated
        - Constructive tone maintained

    - id: stage7-feedback-loop
      name: Feedback & Improvement Loop
      duration: 1 minute
      inputs:
        - Review report
      actions:
        - Post review report as JIRA comment
        - If Critical Issues: Change ticket status to "Needs Revision"
        - Assign ticket back to analyst
        - Save review report locally
      outputs:
        - Review comment in JIRA
        - Ticket assigned to analyst
        - Local review file
      success_criteria:
        - Review posted successfully
        - Analyst notified

  success_metrics:
    - Total time: <20 minutes
    - All stages completed (optional stage skippable)
    - Review report posted to JIRA
    - Feedback actionable and constructive

  mermaid_diagram: |
    graph TD
      A[Start: Enriched Ticket] --> B[Stage 1: Preparation]
      B --> C[Stage 2: Systematic Evaluation]
      C --> D[Stage 3: Gap Identification]
      D --> E[Stage 4: Bias Detection]
      E --> F{Perform Fact Verification?}
      F -->|Yes| G[Stage 5: Fact Verification]
      F -->|No| H[Stage 6: Documentation]
      G --> H
      H --> I[Stage 7: Feedback Loop]
      I --> J[End: Review Posted]
```

### Workflow Execution Example

**Successful Workflow Execution:**

```
ðŸ” Security Analysis Review Workflow
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Stage 1: Preparation (completed in 2m 15s)
   â†’ Enrichment extracted from JIRA-1234
   â†’ 12 factual claims identified

âœ… Stage 2: Systematic Evaluation (completed in 6m 30s)
   â†’ All 8 checklists executed
   â†’ Overall Quality Score: 78% (Good)

âœ… Stage 3: Gap Identification (completed in 3m 45s)
   â†’ 0 Critical gaps
   â†’ 3 Significant gaps
   â†’ 5 Minor improvements

âœ… Stage 4: Cognitive Bias Detection (completed in 2m 20s)
   â†’ 1 bias detected: Confirmation bias

â­ï¸  Stage 5: Fact Verification (skipped - Perplexity MCP unavailable)

âœ… Stage 6: Review Documentation (completed in 2m 10s)
   â†’ Review report generated (12 sections)

âœ… Stage 7: Feedback Loop (completed in 45s)
   â†’ Review posted to JIRA-1234
   â†’ Ticket assigned to analyst

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Review Complete | Total: 17m 45s
```

**Common Failure Scenarios and Troubleshooting:**

| Error | Cause | Resolution |
|-------|-------|------------|
| "Atlassian MCP not available" | MCP server not configured | Configure Atlassian MCP in Claude Code settings |
| "JIRA ticket not found" | Invalid ticket ID or permissions | Verify ticket ID exists and agent has read permissions |
| "Enrichment comment not found" | Analyst hasn't posted enrichment yet | Ensure Story 3.1 workflow completed before review |
| "Checklist execution failed" | Checklist file missing or malformed | Verify all 8 checklists exist in `checklists/` directory |
| "Review report post failed" | JIRA write permissions issue | Verify agent has comment posting permissions |
| Workflow exceeds 20 minutes | Large enrichment or slow network | Acceptable for complex reviews; log for investigation if >25 min |

### Story 3.4 Integration: Priority-Based Review Triggering

**Dependency Type:** Future Integration (Story 3.4 can be developed in parallel)

**Integration Point:** Story 3.4 defines the triggering logic that determines WHEN this review workflow executes. This story (3.2) defines WHAT HAPPENS during the review workflow.

**Workflow Triggering:**

```yaml
# Defined in Story 3.4, referenced here for context
review_triggers:
  mandatory:
    - P1 (Critical priority): 100% of enrichments reviewed
    - P2 (High priority): 100% of enrichments reviewed
  sampling:
    - P3 (Medium): 25% random sampling
    - P4 (Low): 10% random sampling
    - P5 (Info): 5% random sampling

  assignment:
    - P1/P2: Assign to senior reviewer
    - P3/P4/P5: Assign to any available reviewer
```

**Testing Implications:**

- This story (3.2) can be tested independently with manual workflow invocation
- Story 3.4 integration testing requires both stories completed
- Story 3.4 determines ticket routing; this story executes the review process

**Integration Hooks:**

- Story 3.4 calls this workflow's orchestration task: `*review-security-enrichment {ticket-id}`
- This workflow is agnostic to how it was triggered (manual, automatic, or sampling-based)
- Future: Story 3.3 (Lifecycle Workflow) will orchestrate both 3.1 â†’ 3.4 â†’ 3.2 sequence

### Testing

**Test Location:** `expansion-packs/bmad-1898-engineering/tests/workflows/`

**Test Framework:** pytest (Python-based workflow testing)

**Test Standards:**

- End-to-end integration test with real enrichment
- Mock MCP interactions for unit tests (Atlassian and Perplexity)
- Test with various quality levels (excellent, good, poor, critical errors)
- Measure and validate total workflow execution time (target: 15-20 min)
- Verify constructive tone maintained in all review reports
- Test feedback loop triggers analyst action (status change, assignment)
- Test error handling for missing MCP services
- Validate all 8 quality dimension checklists execute correctly

**Test Data Requirements:**

- Sample enrichments with known quality scores:
  - `test-enrichment-excellent.md` (90%+ quality, minimal gaps)
  - `test-enrichment-good.md` (75-89% quality, some gaps)
  - `test-enrichment-needs-improvement.md` (60-74% quality, many gaps)
  - `test-enrichment-inadequate.md` (<60% quality, critical errors)
- Mock JIRA ticket responses (JSON fixtures)
- Mock Perplexity fact verification responses
- Sample fact verification claims (CVSS, EPSS, KEV, patches)

**Mocking Strategy:**

- **Atlassian MCP**: Mock ticket read and comment posting operations
- **Perplexity MCP**: Mock fact verification responses with known data
- **File System**: Use temp directories for artifact storage during tests
- **Time Tracking**: Mock time.time() for deterministic execution time tests

**Performance Benchmarks:**

- Stage 1 (Preparation): <3 minutes
- Stage 2 (Evaluation): <7 minutes
- Stage 3 (Gap Identification): <4 minutes
- Stage 4 (Bias Detection): <3 minutes
- Stage 5 (Fact Verification): <5 minutes (if performed)
- Stage 6 (Documentation): <3 minutes
- Stage 7 (Feedback Loop): <1 minute
- **Total: <20 minutes for 90% of executions**

**Test Cases:**

1. **Excellent enrichment (90%+)**: Review mostly positive, few minor improvements suggested
2. **Good enrichment with gaps (75-89%)**: Balanced review, significant gaps identified
3. **Poor enrichment (<60%)**: Many gaps but constructive tone maintained
4. **Enrichment with critical errors**: Critical issues identified, ticket status â†’ "Needs Revision"
5. **Optional fact verification**: Test with and without Perplexity MCP available
6. **MCP unavailable scenarios**:
   - Atlassian MCP unavailable â†’ workflow halts with clear error message
   - Perplexity MCP unavailable â†’ fact verification skipped, documented in report
7. **Time performance**: Workflow completes within target time for all quality levels

## Change Log

| Date       | Version | Description                                                                                                                                                                                                 | Author     |
| ---------- | ------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |
| 2025-11-08 | 1.1     | Remediation: Enhanced AC measurability, added MCP prerequisite verification tasks, improved task granularity, added Story 3.4 integration clarification, enhanced testing standards, added workflow examples | Sarah (PO) |
| 2025-11-06 | 1.0     | Initial story creation                                                                                                                                                                                      | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated during development_

### Debug Log References

_To be populated during development_

### Completion Notes List

_To be populated during development_

### File List

_To be populated during development_

## QA Results

_To be populated after QA review_
