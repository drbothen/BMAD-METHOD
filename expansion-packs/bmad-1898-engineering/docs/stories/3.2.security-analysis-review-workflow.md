# Story 3.2: Security Analysis Review Workflow

## Status

Draft

## Story

**As a** security operations team,
**I want** a systematic peer review workflow,
**so that** quality assurance is thorough and consistent.

## Acceptance Criteria

1. Workflow includes: Preparation → Evaluation → Gap Identification → Bias Detection → (Optional) Fact Verification → Documentation → Feedback Loop
2. Workflow takes 15-20 minutes
3. Workflow produces review report in JIRA
4. Workflow triggers analyst improvements

## Tasks / Subtasks

- [ ] Create review workflow definition (AC: 1, 2)
  - [ ] Create `workflows/security-analysis-review-workflow.yaml`
  - [ ] Define all 7 workflow stages
  - [ ] Specify inputs/outputs for each stage
  - [ ] Add Mermaid diagram
  - [ ] Include time estimates per stage
- [ ] Define Stage 1: Preparation (AC: 1)
  - [ ] Input: JIRA ticket ID with enrichment
  - [ ] Actions: Read ticket, read enrichment comment, extract claims
  - [ ] Output: Enrichment to review, claims list
  - [ ] Time: 2-3 minutes
- [ ] Define Stage 2: Systematic Evaluation (AC: 1)
  - [ ] Input: Enrichment document
  - [ ] Actions: Run 8 quality dimension checklists
  - [ ] Output: Quality scores per dimension, overall score
  - [ ] Time: 5-7 minutes
- [ ] Define Stage 3: Gap Identification (AC: 1)
  - [ ] Input: Checklist results
  - [ ] Actions: Categorize gaps as Critical/Significant/Minor
  - [ ] Output: Structured findings with recommendations
  - [ ] Time: 3-4 minutes
- [ ] Define Stage 4: Cognitive Bias Detection (AC: 1)
  - [ ] Input: Enrichment document
  - [ ] Actions: Run cognitive bias checklist
  - [ ] Output: Detected biases with debiasing strategies
  - [ ] Time: 2-3 minutes
- [ ] Define Stage 5: Fact Verification (Optional) (AC: 1)
  - [ ] Input: Critical claims (CVSS, KEV, etc.)
  - [ ] Actions: Verify against authoritative sources via Perplexity
  - [ ] Output: Accuracy score, discrepancies
  - [ ] Time: 3-5 minutes (if performed)
- [ ] Define Stage 6: Review Documentation (AC: 1, 3)
  - [ ] Input: All review findings
  - [ ] Actions: Generate review report using template
  - [ ] Output: Constructive review report
  - [ ] Time: 2-3 minutes
- [ ] Define Stage 7: Feedback Loop (AC: 1, 4)
  - [ ] Input: Review report
  - [ ] Actions: Post review to JIRA, assign back to analyst
  - [ ] Output: Review comment in JIRA, analyst notified
  - [ ] Time: 1 minute
- [ ] Create workflow orchestration task (AC: 2, 3, 4)
  - [ ] Create `tasks/review-security-enrichment.md`
  - [ ] Implement complete workflow execution
  - [ ] Total time target: 15-20 minutes
  - [ ] Ensure review posted to JIRA
  - [ ] Trigger analyst improvements

## Dev Notes

### Workflow YAML Structure

```yaml
workflow:
  id: security-analysis-review-v1
  name: Security Analysis Review Workflow
  version: 1.0
  description: Systematic peer review workflow for security enrichments
  estimated_duration: 15-20 minutes
  prerequisites:
    - JIRA ticket with analyst enrichment
    - Security Reviewer agent activated
    - Atlassian MCP configured
    - (Optional) Perplexity MCP for fact verification

  stages:
    - id: stage1-preparation
      name: Review Preparation
      duration: 2-3 minutes
      inputs:
        - JIRA ticket ID
      actions:
        - Read JIRA ticket via Atlassian MCP
        - Extract analyst enrichment comment
        - Parse enrichment structure
        - Extract factual claims for verification
      outputs:
        - Enrichment document
        - Claims list (CVSS, EPSS, KEV, etc.)
        - Analyst name
      success_criteria:
        - Enrichment successfully extracted
        - Claims identified

    - id: stage2-evaluation
      name: Systematic Quality Evaluation
      duration: 5-7 minutes
      inputs:
        - Enrichment document
      actions:
        - Execute technical-accuracy-checklist.md
        - Execute completeness-checklist.md
        - Execute actionability-checklist.md
        - Execute contextualization-checklist.md
        - Execute documentation-quality-checklist.md
        - Execute attack-mapping-validation-checklist.md
        - Execute cognitive-bias-checklist.md
        - Execute source-citation-checklist.md
        - Calculate scores per dimension
        - Calculate overall quality score
      outputs:
        - 8 dimension scores (percentages)
        - Overall quality score
        - Quality classification (Excellent/Good/Needs Improvement/Inadequate)
      success_criteria:
        - All 8 checklists executed
        - Overall score calculated

    - id: stage3-gap-identification
      name: Gap Identification & Categorization
      duration: 3-4 minutes
      inputs:
        - Checklist results
        - Failed checklist items
      actions:
        - Categorize each gap as Critical/Significant/Minor
        - Specify location for each gap
        - Explain impact of each gap
        - Provide recommended fixes
        - Link to learning resources
      outputs:
        - Critical issues list
        - Significant gaps list
        - Minor improvements list
      success_criteria:
        - All gaps categorized
        - Recommendations provided

    - id: stage4-bias-detection
      name: Cognitive Bias Detection
      duration: 2-3 minutes
      inputs:
        - Enrichment document
      actions:
        - Check for confirmation bias
        - Check for anchoring bias
        - Check for availability heuristic
        - Check for overconfidence bias
        - Check for recency bias
        - Provide specific examples
        - Suggest debiasing strategies
      outputs:
        - Detected biases with examples
        - Debiasing recommendations
      success_criteria:
        - Bias assessment complete
        - Constructive feedback provided

    - id: stage5-fact-verification
      name: Fact Verification (Optional)
      duration: 3-5 minutes
      optional: true
      inputs:
        - Claims list (CVSS, EPSS, KEV, patches)
      actions:
        - Verify CVSS score against NVD
        - Verify EPSS score against FIRST
        - Verify KEV status against CISA
        - Verify patch versions against vendor
        - Compare analyst claims with authoritative data
        - Document discrepancies
      outputs:
        - Accuracy score (% correct)
        - Discrepancies list with corrections
      success_criteria:
        - Critical claims verified
        - Discrepancies documented

    - id: stage6-documentation
      name: Review Report Documentation
      duration: 2-3 minutes
      inputs:
        - Quality scores
        - Gap findings
        - Bias detection results
        - Fact verification results (if performed)
      actions:
        - Use security-review-report-tmpl.yaml
        - Acknowledge strengths first
        - Document findings constructively
        - Provide prioritized recommendations
        - Link learning resources
        - Maintain blameless tone
      outputs:
        - Constructive review report (markdown)
      success_criteria:
        - All sections populated
        - Constructive tone maintained

    - id: stage7-feedback-loop
      name: Feedback & Improvement Loop
      duration: 1 minute
      inputs:
        - Review report
      actions:
        - Post review report as JIRA comment
        - If Critical Issues: Change ticket status to "Needs Revision"
        - Assign ticket back to analyst
        - Save review report locally
      outputs:
        - Review comment in JIRA
        - Ticket assigned to analyst
        - Local review file
      success_criteria:
        - Review posted successfully
        - Analyst notified

  success_metrics:
    - Total time: <20 minutes
    - All stages completed (optional stage skippable)
    - Review report posted to JIRA
    - Feedback actionable and constructive

  mermaid_diagram: |
    graph TD
      A[Start: Enriched Ticket] --> B[Stage 1: Preparation]
      B --> C[Stage 2: Systematic Evaluation]
      C --> D[Stage 3: Gap Identification]
      D --> E[Stage 4: Bias Detection]
      E --> F{Perform Fact Verification?}
      F -->|Yes| G[Stage 5: Fact Verification]
      F -->|No| H[Stage 6: Documentation]
      G --> H
      H --> I[Stage 7: Feedback Loop]
      I --> J[End: Review Posted]
```

### Priority-Based Review Triggering (Story 3.4 Integration)

```yaml
review_triggers:
  mandatory:
    - P1 (Critical priority)
    - P2 (High priority)
  sampling:
    - P3 (Medium): 25% random sampling
    - P4 (Low): 10% random sampling
    - P5 (Info): 5% random sampling

  assignment:
    - P1/P2: Assign to senior reviewer
    - P3/P4/P5: Assign to any available reviewer
```

### Testing

**Test Location:** `expansion-packs/bmad-1898-engineering/tests/workflows/`

**Test Standards:**

- End-to-end integration test with real enrichment
- Test with various quality levels
- Measure total workflow execution time
- Verify constructive tone maintained
- Test feedback loop triggers analyst action

**Test Cases:**

1. Excellent enrichment (90%+): Review should be mostly positive
2. Good enrichment with gaps: Balanced review
3. Poor enrichment (<60%): Many gaps but constructive
4. Enrichment with critical errors: Identify must-fix issues
5. Optional fact verification: Test with and without

## Change Log

| Date       | Version | Description            | Author     |
| ---------- | ------- | ---------------------- | ---------- |
| 2025-11-06 | 1.0     | Initial story creation | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated during development_

### Debug Log References

_To be populated during development_

### Completion Notes List

_To be populated during development_

### File List

_To be populated during development_

## QA Results

_To be populated after QA review_
