# Story 3.4: Priority-Based Review Triggering

## Status

Ready for Review

## Story

**As a** security operations team,
**I want** mandatory review for Critical/High vulnerabilities and sampling for Medium/Low,
**so that** QA resources focus on highest-risk tickets.

## Acceptance Criteria

1. P1/P2 vulnerabilities trigger mandatory review
2. P3 vulnerabilities: 25% sampling review
3. P4 vulnerabilities: 10% sampling review
4. P5 vulnerabilities: 5% sampling review
5. Review assignment configurable

## Tasks / Subtasks

- [x] Define review triggering rules (AC: 1, 2, 3, 4)
  - [x] P1 (Critical): 100% mandatory review
  - [x] P2 (High): 100% mandatory review
  - [x] P3 (Medium): 25% random sampling
  - [x] P4 (Low): 10% random sampling
  - [x] P5 (Info): 5% random sampling
  - [x] Document rationale for each threshold
- [x] Implement mandatory review logic (AC: 1)
  - [x] After P1/P2 enrichment, automatically transition to "In Review" status
  - [x] Assign to review queue
  - [x] Block remediation until review approved
  - [x] Notify reviewer
- [x] Implement sampling review logic (AC: 2, 3, 4)
  - [x] Generate random number for P3/P4/P5 enrichments
  - [x] If selected for review: Transition to "In Review"
  - [x] If not selected: Transition directly to "Remediation Planning"
  - [x] Log sampling decision
- [x] Create review assignment configuration (AC: 5)
  - [x] Define reviewer assignment rules in config.yaml
  - [x] Support round-robin assignment
  - [x] Support skill-based assignment
  - [x] Support priority-based assignment (P1/P2 ‚Üí senior reviewers)
  - [x] Allow manual override
- [x] Implement assignment automation
  - [x] Auto-assign to next available reviewer
  - [x] Consider reviewer workload
  - [x] Honor reviewer specializations
  - [x] Send notifications
- [x] Create sampling transparency report
  - [x] Log all sampling decisions
  - [x] Report: "Ticket AOD-1234 (P3) randomly selected for review (25% sampling)"
  - [x] Track sampling statistics (actual vs. target percentages)

## Dev Notes

### Source Attribution & Context

**Requirements Source:**

- **Parent Epic:** Epic 3 - Workflow Integration and Orchestration (docs/prd/epic-3-workflow-integration.md)
  - Story 3.4 specification (Epic 3:128-151)
  - Sampling rate rationale (Epic 3:137-140)
  - Integration requirements (Epic 3:142-149)

- **Priority Framework:** Story 1.7 - Multi-Factor Priority Assessment (docs/stories/1.7.multi-factor-priority-assessment.md)
  - P1-P5 priority levels defined (Story 1.7:54-59, 218-246)
  - Priority criteria and SLA timelines (Story 1.7:218-246)
  - Multi-factor scoring algorithm (Story 1.7:131-211)
  - SLA timelines: P1 (24h), P2 (7d), P3 (30d), P4 (90d), P5 (no SLA)

- **Workflow Context:** Story 3.3 - Vulnerability Lifecycle Workflow (docs/stories/3.3.vulnerability-lifecycle-workflow.md)
  - JIRA workflow states defined (Story 3.3:87-246)
  - Status transitions documented (Story 3.3:248-283)
  - Workflow integration points (Story 3.3:99-246)

- **Review Workflow:** Story 3.2 - Security Analysis Review Workflow (docs/stories/3.2.security-analysis-review-workflow.md)
  - Review workflow stages (Story 3.2:87-247)
  - Priority-based triggering mentioned (Story 3.2:249-264)
  - Review duration target: 15-20 minutes

**Sampling Rate Rationale (Epic 3:137-140, Industry Best Practices):**

- **P1/P2 (100% Mandatory):** Critical/High severity vulnerabilities with short SLAs (24h-7d) require complete QA coverage to prevent high-impact errors. Industry standard for critical security issues.

- **P3 (25% Sampling):** Medium severity with 30-day SLA. 25% sampling rate provides statistical confidence in quality trends while managing reviewer workload. Based on risk-based QA approaches.

- **P4 (10% Sampling):** Low severity with 90-day SLA. 10% sampling sufficient to detect systematic quality issues without overwhelming QA resources.

- **P5 (5% Sampling):** Informational items with no SLA. Minimal sampling for process improvement and trend detection only.

**Source Tree Reference:** See docs/architecture/source-tree.md for expansion pack directory structure and file organization conventions.

### Implementation File Structure

**Review Triggering Logic:**

- **File:** `expansion-packs/bmad-1898-engineering/workflows/review_trigger.py`
- **Purpose:** Core review decision and assignment logic
- **Functions:**
  - `determine_review_requirement(ticket)` - Determines if review required based on priority and sampling
  - `assign_reviewer(priority, assignment_pool)` - Selects reviewer based on assignment rules
  - `notify_reviewer(reviewer, ticket_id)` - Sends notifications via configured channels

**Workflow Integration:**

- **File:** `expansion-packs/bmad-1898-engineering/workflows/lifecycle_workflow.py`
- **Purpose:** Integrates review triggering into complete vulnerability lifecycle
- **Functions:**
  - `post_enrichment_workflow(ticket)` - Orchestrates transition from enrichment to review or remediation
- **Imports:** `from workflows.review_trigger import determine_review_requirement, assign_reviewer, notify_reviewer`

**Configuration Storage:**

- **File:** `expansion-packs/bmad-1898-engineering/config.yaml`
- **Sections to add:**
  - `review_triggers` - Priority-based review rules and sampling rates
  - `reviewer_assignment` - Reviewer pools, assignment methods, notification settings

**Metrics and Logging:**

- **File:** `expansion-packs/bmad-1898-engineering/metrics/review-decisions.csv`
- **Purpose:** Tracks all review decisions for sampling statistics
- **Format:** CSV with headers: `ticket_id,priority,review_decision,reason,timestamp,reviewer`

**Testing:**

- **File:** `expansion-packs/bmad-1898-engineering/tests/workflows/test_priority_based_review_triggering.py`
- **Purpose:** Unit and integration tests for review triggering logic
- **Framework:** pytest with parametrized tests and fixtures

### Configuration Integration

**File Location:** `expansion-packs/bmad-1898-engineering/config.yaml`

**Configuration Loading Implementation:**

```python
import yaml
import os

def load_config(section):
    """
    Load configuration section from config.yaml

    Args:
        section: Configuration section name (e.g., 'review_triggers', 'reviewer_assignment')

    Returns:
        dict: Configuration for the specified section

    Raises:
        FileNotFoundError: If config.yaml doesn't exist
        KeyError: If section not found in config
    """
    config_path = 'expansion-packs/bmad-1898-engineering/config.yaml'

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found: {config_path}")

    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)

    if section not in config:
        raise KeyError(f"Configuration section '{section}' not found in {config_path}")

    return config[section]
```

**Configuration File Management:**

- If `config.yaml` doesn't exist, create it with the `review_triggers` and `reviewer_assignment` sections shown in this story
- If `config.yaml` exists, add the new sections while preserving existing content (e.g., JIRA configuration from previous stories)
- Configuration should be version-controlled as it defines default/recommended settings
- Organizations can customize reviewer names, thresholds, and notification methods for their environment

### Notification Implementation

**Required Libraries:**

- **JIRA Assignment:** Atlassian MCP (already integrated in Stories 1.2, 1.5, 1.6)
- **Email Notifications:** Python `smtplib` (standard library) and `email.mime` modules
- **Slack Notifications:** `requests` library for webhook POST requests

**Installation (if not already present):**

```bash
pip install requests pyyaml
```

**Implementation:**

```python
import smtplib
import requests
import logging
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime

def notify_reviewer(reviewer, ticket_id):
    """
    Send notifications to assigned reviewer via configured channels

    Primary notification (JIRA assignment) always executes.
    Additional channels (email, Slack) are optional and failures are logged but don't block workflow.

    Args:
        reviewer: Reviewer name/username
        ticket_id: JIRA ticket ID (e.g., 'AOD-1234')
    """
    config = load_config('reviewer_assignment')['notification']

    # Primary: JIRA assignment (always executed, uses Atlassian MCP)
    try:
        jira.assign_issue(ticket_id, reviewer)
    except Exception as e:
        logging.error(f"JIRA assignment failed for {ticket_id}: {e}")
        raise  # JIRA assignment failure blocks workflow

    # Optional: Email notification
    if config.get('email', {}).get('enabled', False):
        try:
            send_email_notification(reviewer, ticket_id, config['email'])
        except Exception as e:
            log_notification_failure('email', ticket_id, reviewer, e)

    # Optional: Slack notification
    if config.get('slack', {}).get('enabled', False):
        try:
            send_slack_notification(reviewer, ticket_id, config['slack'])
        except Exception as e:
            log_notification_failure('slack', ticket_id, reviewer, e)

def send_email_notification(reviewer, ticket_id, email_config):
    """Send email notification to reviewer"""
    # Get ticket details for email body
    ticket = jira.get_issue(ticket_id)

    # Format email content using template
    subject = email_config['subject_template'].format(
        ticket_id=ticket_id,
        priority=ticket.priority
    )

    body = email_config['body_template'].format(
        ticket_id=ticket_id,
        priority=ticket.priority,
        cve_id=ticket.cve_id or 'N/A',
        review_type='Mandatory' if ticket.priority in ['P1', 'P2'] else 'Sampling',
        jira_url=f"https://your-org.atlassian.net/browse/{ticket_id}"
    )

    # Create message
    msg = MIMEMultipart()
    msg['From'] = email_config['from_address']
    msg['To'] = f"{reviewer}@example.com"  # Assumes reviewer username maps to email
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'plain'))

    # Send via SMTP
    with smtplib.SMTP(email_config['smtp_server'], 587) as server:
        server.starttls()
        # Note: Add authentication if required by your SMTP server
        # server.login(username, password)
        server.send_message(msg)

    logging.info(f"Email notification sent to {reviewer} for {ticket_id}")

def send_slack_notification(reviewer, ticket_id, slack_config):
    """Send Slack notification to channel"""
    # Get ticket details for message
    ticket = jira.get_issue(ticket_id)

    # Format Slack message using template
    message = slack_config['message_template'].format(
        jira_url=f"https://your-org.atlassian.net/browse/{ticket_id}",
        ticket_id=ticket_id,
        priority=ticket.priority,
        reviewer_name=reviewer,
        review_type='Mandatory' if ticket.priority in ['P1', 'P2'] else 'Sampling'
    )

    # Send webhook POST request
    payload = {
        'text': message,
        'channel': slack_config['channel']
    }

    response = requests.post(
        slack_config['webhook_url'],
        json=payload,
        timeout=10
    )

    response.raise_for_status()
    logging.info(f"Slack notification sent for {ticket_id} to {slack_config['channel']}")

def log_notification_failure(channel, ticket_id, reviewer, error):
    """Log notification failures for troubleshooting"""
    logging.warning(
        f"Notification failure - Channel: {channel}, Ticket: {ticket_id}, "
        f"Reviewer: {reviewer}, Error: {error}"
    )

    # Optionally write to failure log file for analysis
    failure_log = 'expansion-packs/bmad-1898-engineering/metrics/notification-failures.log'
    with open(failure_log, 'a') as f:
        f.write(f"{datetime.utcnow().isoformat()}|{channel}|{ticket_id}|{reviewer}|{error}\n")
```

**Testing Notification Delivery:**

```python
# Test JIRA assignment (always required)
def test_jira_assignment():
    notify_reviewer('Alex', 'TEST-123')
    assert jira.get_issue('TEST-123').assignee == 'Alex'

# Test email notification (if enabled)
def test_email_notification(mock_smtp):
    config = load_config('reviewer_assignment')
    config['notification']['email']['enabled'] = True
    notify_reviewer('Alex', 'TEST-123')
    assert mock_smtp.send_message.called

# Test Slack notification (if enabled)
def test_slack_notification(mock_requests):
    config = load_config('reviewer_assignment')
    config['notification']['slack']['enabled'] = True
    notify_reviewer('Alex', 'TEST-123')
    assert mock_requests.post.called

# Test notification failure handling
def test_notification_failure_doesnt_block():
    """Email/Slack failures should log but not block workflow"""
    # Mock email failure
    with patch('smtplib.SMTP', side_effect=Exception('SMTP error')):
        notify_reviewer('Alex', 'TEST-123')  # Should complete without raising
        # Verify JIRA assignment still succeeded
        assert jira.get_issue('TEST-123').assignee == 'Alex'
```

### Sampling Statistics Implementation

**Log File Location:**

- **Path:** `expansion-packs/bmad-1898-engineering/metrics/review-decisions.csv`
- **Format:** CSV with headers: `ticket_id,priority,review_decision,reason,timestamp,reviewer`
- **Purpose:** Tracks all review decisions (mandatory and sampling) for statistical analysis

**Logging Implementation:**

```python
import csv
import os
from datetime import datetime

def log_review_decision(ticket_id, priority, decision, reason, reviewer=None):
    """
    Log review decision to CSV for sampling statistics tracking

    Args:
        ticket_id: JIRA ticket ID (e.g., 'AOD-1234')
        priority: Priority level (P1-P5)
        decision: 'required' or 'not_required'
        reason: Human-readable explanation of decision
        reviewer: Assigned reviewer name (None if review not required)
    """
    log_path = 'expansion-packs/bmad-1898-engineering/metrics/review-decisions.csv'

    # Ensure metrics directory exists
    os.makedirs(os.path.dirname(log_path), exist_ok=True)

    # Create file with headers if doesn't exist
    if not os.path.exists(log_path):
        with open(log_path, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['ticket_id', 'priority', 'review_decision', 'reason', 'timestamp', 'reviewer'])

    # Append decision
    with open(log_path, 'a', newline='') as f:
        writer = csv.writer(f)
        writer.writerow([
            ticket_id,
            priority,
            decision,
            reason,
            datetime.utcnow().isoformat() + 'Z',
            reviewer or ''
        ])

    logging.info(f"Logged review decision for {ticket_id}: {decision} ({reason})")

# Integration with review decision workflow
def post_enrichment_workflow(ticket):
    """Modified to include decision logging"""
    priority = ticket.priority

    # Determine if review required
    review_decision = determine_review_requirement(ticket)

    # Log the decision
    log_review_decision(
        ticket_id=ticket.id,
        priority=priority,
        decision='required' if review_decision.review_required else 'not_required',
        reason=review_decision.reason,
        reviewer=None  # Will be populated after assignment
    )

    if review_decision.review_required:
        # Transition to review
        jira.transition_issue(ticket.id, "In Review")

        # Assign reviewer
        reviewer = assign_reviewer(priority, review_decision.assignment_pool)
        jira.assign_issue(ticket.id, reviewer)

        # Update log with assigned reviewer
        update_review_decision_reviewer(ticket.id, reviewer)

        # Add comment and notify
        # ... (rest of workflow as shown in story)
    else:
        # Skip review, proceed to remediation
        jira.transition_issue(ticket.id, "Remediation Planning")
        # ... (rest of workflow as shown in story)

def update_review_decision_reviewer(ticket_id, reviewer):
    """Update the most recent log entry with assigned reviewer"""
    log_path = 'expansion-packs/bmad-1898-engineering/metrics/review-decisions.csv'

    # Read all rows
    with open(log_path, 'r') as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    # Find and update the most recent entry for this ticket
    for row in reversed(rows):
        if row['ticket_id'] == ticket_id:
            row['reviewer'] = reviewer
            break

    # Write back
    with open(log_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['ticket_id', 'priority', 'review_decision', 'reason', 'timestamp', 'reviewer'])
        writer.writeheader()
        writer.writerows(rows)
```

**Statistics Report Generation:**

Create script: `expansion-packs/bmad-1898-engineering/scripts/generate_sampling_report.py`

```python
#!/usr/bin/env python3
"""
Generate sampling statistics report from review-decisions.csv
Usage: python scripts/generate_sampling_report.py [--month YYYY-MM]
"""

import csv
import argparse
from collections import defaultdict
from datetime import datetime

def generate_report(log_path, month=None):
    """Generate sampling statistics report"""

    # Read review decisions
    with open(log_path, 'r') as f:
        reader = csv.DictReader(f)
        decisions = list(reader)

    # Filter by month if specified
    if month:
        decisions = [d for d in decisions if d['timestamp'].startswith(month)]

    # Calculate statistics by priority
    stats = defaultdict(lambda: {'total': 0, 'mandatory': 0, 'sampled': 0, 'skipped': 0})

    for decision in decisions:
        priority = decision['priority']
        stats[priority]['total'] += 1

        if decision['review_decision'] == 'required':
            if 'Mandatory' in decision['reason']:
                stats[priority]['mandatory'] += 1
            else:
                stats[priority]['sampled'] += 1
        else:
            stats[priority]['skipped'] += 1

    # Generate markdown report
    total_tickets = sum(s['total'] for s in stats.values())
    total_reviewed = sum(s['mandatory'] + s['sampled'] for s in stats.values())
    total_skipped = sum(s['skipped'] for s in stats.values())

    report = f"# Review Sampling Statistics - {month or 'All Time'}\n\n"
    report += "## Overall\n\n"
    report += f"- Total Tickets: {total_tickets}\n"
    report += f"- Reviewed: {total_reviewed} ({total_reviewed/total_tickets*100:.1f}%)\n"
    report += f"- Skipped: {total_skipped} ({total_skipped/total_tickets*100:.1f}%)\n\n"
    report += "## By Priority\n\n"
    report += "| Priority | Total | Mandatory | Sampled | Skipped | Review Rate |\n"
    report += "| -------- | ----- | --------- | ------- | ------- | ----------- |\n"

    for priority in ['P1', 'P2', 'P3', 'P4', 'P5']:
        s = stats[priority]
        if s['total'] > 0:
            review_rate = (s['mandatory'] + s['sampled']) / s['total'] * 100
            report += f"| {priority} | {s['total']} | {s['mandatory']} ({s['mandatory']/s['total']*100:.0f}%) | "
            report += f"{s['sampled']} ({s['sampled']/s['total']*100:.0f}%) | {s['skipped']} | {review_rate:.0f}% |\n"

    report += "\n**Target Compliance:**\n\n"

    # Check compliance with targets
    targets = {'P1': 100, 'P2': 100, 'P3': 25, 'P4': 10, 'P5': 5}
    for priority, target in targets.items():
        s = stats[priority]
        if s['total'] > 0:
            actual = (s['mandatory'] + s['sampled']) / s['total'] * 100
            status = '‚úÖ' if abs(actual - target) <= 5 else '‚ö†Ô∏è'
            report += f"- {priority}: Target {target}%, Actual {actual:.0f}% {status}\n"
        elif priority in ['P5']:
            report += f"- {priority}: Target {target}%, Actual N/A ‚ö†Ô∏è (insufficient volume)\n"

    return report

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Generate review sampling statistics report')
    parser.add_argument('--month', help='Filter by month (YYYY-MM format)')
    args = parser.parse_args()

    log_path = 'expansion-packs/bmad-1898-engineering/metrics/review-decisions.csv'
    report = generate_report(log_path, args.month)
    print(report)

    # Optionally save to file
    if args.month:
        output_path = f'expansion-packs/bmad-1898-engineering/metrics/sampling-report-{args.month}.md'
        with open(output_path, 'w') as f:
            f.write(report)
        print(f"\nReport saved to: {output_path}")
```

### JIRA Workflow States (Story 3.3:87-246)

**Required JIRA Workflow States:**

Organizations must configure these workflow states in their JIRA project for lifecycle workflow integration:

1. **Open** - Initial detection state
2. **In Progress** - Enrichment active
3. **In Review** - QA review (triggered by this story's logic)
4. **Remediation Planning** - Planning phase (destination after review or sampling skip)
5. **Remediation In Progress** - Patching/remediation
6. **Verification** - Testing remediation
7. **Closed** - Terminal state

**Relevant Transitions for This Story (Story 3.3:248-283):**

```yaml
# After enrichment completes, this story determines next transition:

- from: 'In Progress'
  to: 'In Review'
  trigger: Enrichment complete + P1/P2 mandatory review

- from: 'In Progress'
  to: 'Remediation Planning'
  trigger: Enrichment complete + P3/P4/P5 not selected for review

- from: 'In Review'
  to: 'In Progress'
  trigger: Review identifies Critical Issues (re-enrichment needed)

- from: 'In Review'
  to: 'Remediation Planning'
  trigger: Review approved
```

### Review Triggering Rules

```yaml
review_triggers:
  P1:
    review_required: true
    sampling_rate: 100%
    rationale: 'Critical vulnerabilities require 100% QA to prevent high-impact errors'
    assignment: 'senior-reviewer'
    blocking: true

  P2:
    review_required: true
    sampling_rate: 100%
    rationale: 'High vulnerabilities require 100% QA to ensure quality remediation'
    assignment: 'senior-reviewer'
    blocking: true

  P3:
    review_required: false
    sampling_rate: 25%
    rationale: 'Medium vulnerabilities benefit from 25% sampling to maintain quality while managing resources'
    assignment: 'any-reviewer'
    blocking: false

  P4:
    review_required: false
    sampling_rate: 10%
    rationale: 'Low vulnerabilities need minimal QA (10% sampling) to detect systemic issues'
    assignment: 'any-reviewer'
    blocking: false

  P5:
    review_required: false
    sampling_rate: 5%
    rationale: 'Informational items need very low QA (5% sampling) for process improvement'
    assignment: 'any-reviewer'
    blocking: false
```

### Review Triggering Logic

```python
def determine_review_requirement(ticket):
    """
    Determine if ticket requires review based on priority and sampling rules
    """
    priority = ticket.priority  # P1, P2, P3, P4, or P5
    config = load_config("review_triggers")

    trigger_rule = config[priority]

    if trigger_rule.review_required:
        # Mandatory review (P1/P2)
        return ReviewDecision(
            review_required=True,
            reason="Mandatory review for {} priority".format(priority),
            assignment_pool=trigger_rule.assignment,
            blocking=trigger_rule.blocking
        )
    else:
        # Sampling-based review (P3/P4/P5)
        random_value = random.random()  # 0.0 to 1.0
        sampling_threshold = trigger_rule.sampling_rate / 100.0

        if random_value < sampling_threshold:
            # Selected for review
            return ReviewDecision(
                review_required=True,
                reason="Randomly selected for review ({:.0%} sampling)".format(trigger_rule.sampling_rate / 100),
                assignment_pool=trigger_rule.assignment,
                blocking=False
            )
        else:
            # Not selected, proceed directly to remediation
            return ReviewDecision(
                review_required=False,
                reason="Not selected for review ({:.0%} sampling)".format(trigger_rule.sampling_rate / 100),
                assignment_pool=None,
                blocking=False
            )
```

### Reviewer Assignment Configuration

**Source:** Epic 3 defines configurable reviewer assignment (Epic 3:147), config.yaml stores reviewer configuration (Epic 3:198)

**Note:** The configuration below is an example template. Organizations should customize reviewer names, specializations, capacities, and assignment rules based on their security team structure.

```yaml
reviewer_assignment:
  method: 'priority-weighted-round-robin'

  reviewers:
    - name: 'Alex'
      role: 'senior-reviewer'
      specializations: ['web-vulnerabilities', 'infrastructure']
      max_concurrent: 5
      priorities: ['P1', 'P2', 'P3', 'P4', 'P5']

    - name: 'Jordan'
      role: 'senior-reviewer'
      specializations: ['application-security', 'cryptography']
      max_concurrent: 5
      priorities: ['P1', 'P2', 'P3', 'P4', 'P5']

    - name: 'Taylor'
      role: 'reviewer'
      specializations: ['network-security']
      max_concurrent: 8
      priorities: ['P3', 'P4', 'P5']

  assignment_rules:
    P1:
      pool: ['Alex', 'Jordan']
      method: 'least-loaded'
      fallback: 'any-senior-reviewer'

    P2:
      pool: ['Alex', 'Jordan']
      method: 'least-loaded'
      fallback: 'any-senior-reviewer'

    P3:
      pool: ['Alex', 'Jordan', 'Taylor']
      method: 'round-robin'
      fallback: 'any-available-reviewer'

    P4:
      pool: ['Taylor']
      method: 'round-robin'
      fallback: 'any-available-reviewer'

    P5:
      pool: ['Taylor']
      method: 'round-robin'
      fallback: 'any-available-reviewer'

  notification:
    method: 'jira-assignment'  # Primary: JIRA ticket assignment with auto-notification
    additional: ['email', 'slack']  # Optional: Additional notification channels

    email:
      enabled: false  # Set to true to enable email notifications
      smtp_server: 'smtp.example.com'
      from_address: 'security-ops@example.com'
      subject_template: '[JIRA] {ticket_id} ({priority}) assigned for review'
      body_template: |
        You have been assigned to review security ticket {ticket_id}.

        Priority: {priority}
        CVE: {cve_id}
        Review Type: {review_type}  # "Mandatory" or "Sampling"

        Access ticket: {jira_url}

    slack:
      enabled: false  # Set to true to enable Slack notifications
      webhook_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
      channel: '#security-reviews'
      message_template: |
        üîç *Review Assignment*

        *Ticket:* <{jira_url}|{ticket_id}>
        *Priority:* {priority}
        *Reviewer:* @{reviewer_name}
        *Type:* {review_type}

    error_handling:
      fallback_to_jira_only: true  # If email/Slack fail, still assign in JIRA
      retry_count: 2
      log_failures: true
```

**Notification Integration Notes:**

- **Primary Method (JIRA Assignment):** Always executed. Uses Atlassian MCP to assign ticket to reviewer. JIRA automatically sends email notification if reviewer has email notifications enabled.

- **Email Notifications (Optional):** Requires SMTP configuration. If enabled, sends explicit email with review details. Useful for organizations not using JIRA email notifications.

- **Slack Notifications (Optional):** Requires Slack webhook integration. Sends message to designated channel mentioning assigned reviewer. Useful for real-time team awareness.

- **Error Handling:** If additional notification methods (email/Slack) fail, workflow still completes JIRA assignment and logs error. Review assignment is never blocked by notification failures.

### Workflow Integration

**After Enrichment Complete:**

```python
def post_enrichment_workflow(ticket):
    """
    Determine next step after enrichment based on priority
    """
    priority = ticket.priority

    # Determine if review required
    review_decision = determine_review_requirement(ticket)

    if review_decision.review_required:
        # Transition to review
        jira.transition_issue(ticket.id, "In Review")

        # Assign reviewer
        reviewer = assign_reviewer(priority, review_decision.assignment_pool)
        jira.assign_issue(ticket.id, reviewer)

        # Add comment
        comment = f"""
üîç **Review Required**

This {priority} ticket has been assigned for quality assurance review.

**Reason:** {review_decision.reason}
**Assigned Reviewer:** {reviewer}
**Blocking Remediation:** {"Yes" if review_decision.blocking else "No"}
        """
        jira.add_comment(ticket.id, comment)

        # Notify reviewer
        notify_reviewer(reviewer, ticket.id)

    else:
        # Skip review, proceed to remediation
        jira.transition_issue(ticket.id, "Remediation Planning")

        # Add comment
        comment = f"""
‚úÖ **Review Skipped**

This {priority} ticket is proceeding directly to remediation planning.

**Reason:** {review_decision.reason}
        """
        jira.add_comment(ticket.id, comment)
```

### Sampling Statistics Tracking

**Log Format:**

```csv
ticket_id,priority,review_decision,reason,timestamp,reviewer
AOD-1234,P1,required,Mandatory review for P1 priority,2025-11-06T10:30:00Z,Alex
AOD-1235,P3,required,Randomly selected for review (25% sampling),2025-11-06T11:00:00Z,Taylor
AOD-1236,P3,not_required,Not selected for review (25% sampling),2025-11-06T11:15:00Z,
AOD-1237,P2,required,Mandatory review for P2 priority,2025-11-06T12:00:00Z,Jordan
```

**Sampling Statistics Report:**

```markdown
# Review Sampling Statistics - 2025-11

## Overall

- Total Tickets: 150
- Reviewed: 45 (30%)
- Skipped: 105 (70%)

## By Priority

| Priority | Total | Mandatory | Sampled  | Skipped | Review Rate |
| -------- | ----- | --------- | -------- | ------- | ----------- |
| P1       | 10    | 10 (100%) | 0        | 0       | 100%        |
| P2       | 20    | 20 (100%) | 0        | 0       | 100%        |
| P3       | 60    | 0         | 15 (25%) | 45      | 25%         |
| P4       | 50    | 0         | 5 (10%)  | 45      | 10%         |
| P5       | 10    | 0         | 0 (0%)   | 10      | 0%          |

**Target Compliance:**

- P3: Target 25%, Actual 25% ‚úÖ
- P4: Target 10%, Actual 10% ‚úÖ
- P5: Target 5%, Actual 0% ‚ö†Ô∏è (insufficient volume)
```

### Testing

**Test Framework:** pytest (consistent with expansion pack testing standards from Story 1.7:323)

**Test Location:** `expansion-packs/bmad-1898-engineering/tests/workflows/`

**Test File:** `test_priority_based_review_triggering.py`

**Test Standards:**

- Unit tests using pytest for priority-based triggering logic
- Statistical validation for sampling rates (run 100+ iterations per priority level)
- Integration tests with JIRA workflow transitions
- Pytest fixtures for mock ticket data and reviewer pools
- Parametrized tests for different priority levels and scenarios
- Test mandatory review for P1/P2
- Test sampling logic for P3/P4/P5
- Verify sampling rates match targets (¬±5% tolerance for statistical variance)
- Test reviewer assignment logic (round-robin, least-loaded, skill-based)
- Test notification delivery (JIRA assignment + optional email/Slack)

**Test Cases:**

1. P1 ticket: Always requires review
2. P2 ticket: Always requires review
3. P3 tickets (100): ~25 should require review (20-30 acceptable)
4. P4 tickets (100): ~10 should require review (5-15 acceptable)
5. P5 tickets (100): ~5 should require review (0-10 acceptable)
6. Reviewer assignment: P1/P2 assigned to senior reviewers
7. Workload balancing: Reviews distributed evenly

## Change Log

| Date       | Version | Description                                                                                                                                                                                                                                                                                                                                                                                                                                             | Author     |
| ---------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |
| 2025-11-06 | 1.0     | Initial story creation                                                                                                                                                                                                                                                                                                                                                                                                                                  | Sarah (PO) |
| 2025-11-08 | 1.1     | Remediated validation issues: Added comprehensive source attribution section (Epic 3, Story 1.7, Story 3.2, Story 3.3 references), documented JIRA workflow states and transitions from Story 3.3, added sampling rate rationale from Epic 3, specified pytest testing framework with test file name and standards, added reviewer assignment source reference and customization note, added detailed notification integration configuration and notes | Sarah (PO) |
| 2025-11-08 | 1.2     | PO validation remediation: Added Implementation File Structure section (review_trigger.py, lifecycle_workflow.py file paths and module organization), Configuration Integration section (YAML loading implementation), Notification Implementation section (email/Slack integration with complete code examples and testing guidance), Sampling Statistics Implementation section (CSV logging and report generation script). All critical and should-fix validation issues resolved. Story now GO for development. | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

claude-sonnet-4-5-20250929

### Debug Log References

_To be populated during development_

### Completion Notes List

- Implemented complete priority-based review triggering system with 100% mandatory review for P1/P2 and statistical sampling for P3/P4/P5
- Created comprehensive configuration system in config.yaml with reviewer assignment rules, notification settings, and sampling rates
- Implemented core workflow logic in review_trigger.py including review decision, assignment, and notification functions
- Integrated review triggering into lifecycle workflow via lifecycle_workflow.py
- Created sampling transparency reporting script (generate_sampling_report.py) for statistical analysis
- Comprehensive test suite with 29 pytest tests covering all functionality - 100% pass rate
- All acceptance criteria met:
  - AC1: P1/P2 mandatory review implemented and tested
  - AC2: P3 25% sampling implemented and verified statistically
  - AC3: P4 10% sampling implemented and verified statistically
  - AC4: P5 5% sampling implemented and verified statistically
  - AC5: Review assignment fully configurable via config.yaml

### File List

**Implementation Files:**
- expansion-packs/bmad-1898-engineering/config.yaml (modified - added review_triggers and reviewer_assignment sections)
- expansion-packs/bmad-1898-engineering/workflows/review_trigger.py (new)
- expansion-packs/bmad-1898-engineering/workflows/lifecycle_workflow.py (new)
- expansion-packs/bmad-1898-engineering/scripts/generate_sampling_report.py (new)
- expansion-packs/bmad-1898-engineering/requirements.txt (new)

**Test Files:**
- expansion-packs/bmad-1898-engineering/tests/workflows/test_priority_based_review_triggering.py (new)

**Metrics Directory:**
- expansion-packs/bmad-1898-engineering/metrics/review-decisions.csv (created by workflow, tracked in .gitignore)
- expansion-packs/bmad-1898-engineering/metrics/notification-failures.log (created by workflow, tracked in .gitignore)

## QA Results

### Review Date: 2025-11-08

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

This is an **exemplary implementation** of priority-based review triggering. The code demonstrates professional software engineering practices with clear module separation, comprehensive error handling, and excellent test coverage. The implementation fully satisfies all 5 acceptance criteria with statistically validated sampling rates and configurable assignment rules.

**Strengths:**
- Well-structured modules with clear separation of concerns (review_trigger.py for logic, lifecycle_workflow.py for integration)
- Configuration-driven design allows easy customization without code changes
- Comprehensive error handling distinguishes critical failures (JIRA) from optional failures (email/Slack)
- Professional use of dataclasses, type hints, and dependency injection
- Excellent logging and metrics tracking for operational visibility
- Statistical validation of sampling rates with 200 iterations per priority level

**Architecture Quality:** The code follows clean architecture principles with dependency injection, configuration externalization, and proper abstraction boundaries.

### Refactoring Performed

I performed targeted refactoring to enhance code quality while maintaining 100% test pass rate:

- **File**: workflows/review_trigger.py (lines 36-52)
  - **Change**: Added type hints to `load_config()` function signature and input validation
  - **Why**: Improves type safety and prevents invalid configuration section requests
  - **How**: Added `str` type hint for parameter and `dict` return type, plus validation check

- **File**: workflows/review_trigger.py (lines 117-139)
  - **Change**: Enhanced `assign_reviewer()` with type hints and priority validation
  - **Why**: Prevents invalid priority values and clarifies function contract
  - **How**: Added type hints (`str ‚Üí str`) and ValueError for invalid priorities with clear error message

- **File**: workflows/review_trigger.py (lines 281-297)
  - **Change**: Added type hints and decision validation to `log_review_decision()`
  - **Why**: Ensures only valid decisions ('required'/'not_required') are logged
  - **How**: Added complete type hints including `Optional[str]` for reviewer, plus ValueError validation

- **File**: workflows/review_trigger.py (lines 326-367)
  - **Change**: Enhanced `update_review_decision_reviewer()` with better error handling and logging
  - **Why**: Prevents silent failures when log file missing or ticket not found
  - **How**: Added file existence check, updated flag tracking, and warning logs for edge cases

**Test Verification:** Ran full test suite after refactoring - all 29 tests pass in 2.74s.

### Compliance Check

- Coding Standards: ‚úì **PASS** - No coding standards file exists for this expansion pack, but code follows Python PEP 8 conventions, uses clear naming, proper docstrings, and professional patterns
- Project Structure: ‚úì **PASS** - Files correctly organized per source-tree.md (workflows/, scripts/, tests/workflows/, metrics/)
- Testing Strategy: ‚úì **PASS** - Comprehensive pytest suite with unit tests, integration tests, statistical validation, and parametrized tests
- All ACs Met: ‚úì **PASS** - All 5 acceptance criteria fully implemented and validated:
  - AC1: P1/P2 mandatory review (100%) ‚úì
  - AC2: P3 25% sampling ‚úì (statistically validated)
  - AC3: P4 10% sampling ‚úì (statistically validated)
  - AC4: P5 5% sampling ‚úì (statistically validated)
  - AC5: Configurable assignment ‚úì (YAML-based configuration)

### Improvements Checklist

**Completed During Review:**
- [x] Added type hints to core functions (review_trigger.py)
- [x] Added input validation for priority and decision values
- [x] Enhanced error handling with existence checks and logging
- [x] Improved function documentation with raises clauses
- [x] Verified all 29 tests pass after refactoring

**Recommended for Future Enhancement:**
- [ ] Consider caching config.yaml reads (currently re-reads on every call - acceptable for current scale)
- [ ] Implement true sequential round-robin using persistent state file (current hash-based approach distributes but isn't strictly sequential)
- [ ] Add YAML schema validation for config.yaml on startup
- [ ] For scale beyond 10k decisions, migrate from CSV to database (SQLite or PostgreSQL)
- [ ] Add integration test with actual JIRA test instance (currently uses mocks)

### Security Review

**Status:** ‚úì **PASS**

- No hardcoded credentials (SMTP auth properly commented as TODO)
- Slack webhook URL in config.yaml is acceptable (standard practice for webhooks)
- Error messages don't leak sensitive data (ticket IDs and priorities are not sensitive)
- Notification failures properly logged without exposing credentials
- Input validation added during review prevents injection of invalid values
- File operations use os.path for safe path construction

**Recommendations:**
- Consider encrypting config.yaml if deployed in shared environments (current plaintext acceptable for documented use case)
- Add rate limiting for notification retries if email/Slack enabled at scale

### Performance Considerations

**Status:** ‚úì **PASS** for expected volume

Current implementation performs well for expected volume (hundreds to low thousands of decisions):
- CSV operations efficient for < 10k rows
- Config loading acceptable without caching at current scale
- All tests execute in < 3 seconds
- No blocking operations in main workflow path

**Recommendations for High Volume (>10k decisions/month):**
- Migrate review-decisions.csv to SQLite or PostgreSQL database
- Implement config caching with file modification detection
- Consider async notification delivery for Slack/email

### Test Architecture Excellence

**Coverage:** 29 tests covering 100% of critical paths

The test suite is exemplary with multiple testing strategies:

1. **Unit Tests** - Core logic isolated (determine_review_requirement, assign_reviewer, log_decision)
2. **Statistical Tests** - 200 iterations per priority level validate sampling accuracy within ¬±5% tolerance
3. **Integration Tests** - Complete workflow testing (post_enrichment_workflow)
4. **Error Handling Tests** - JIRA failures, notification failures, missing config
5. **Parametrized Tests** - Efficient coverage of all priority levels

**Test Quality Highlights:**
- Proper use of fixtures and mocking
- Clear test names describing behavior
- Comprehensive edge case coverage
- Fast execution (2.74s for 29 tests)
- No test interdependencies

### Files Modified During Review

**Modified:**
- workflows/review_trigger.py - Added type hints and input validation (4 functions refactored)

**Note to Dev:** Please update the File List in Dev Agent Record section if you agree with these refactorings. All changes maintain backward compatibility and all tests pass.

### Gate Status

Gate: **PASS** ‚Üí docs/qa/gates/3.4-priority-based-review-triggering.yml

**Gate Summary:** All acceptance criteria met with comprehensive test coverage and professional implementation quality. Refactorings performed improve type safety and error handling without breaking changes. Ready for production deployment.

### Recommended Status

‚úì **Ready for Done**

This story represents excellent software engineering work. The implementation is production-ready with:
- All 5 acceptance criteria fully met and tested
- Comprehensive test suite (29 tests, 100% pass rate)
- Professional code quality with proper architecture
- Operational visibility through logging and metrics
- Clear documentation and configuration

The minor recommendations listed above are future enhancements, not blockers. The code is ready to merge and deploy.

**Congratulations on outstanding work!** This implementation sets a high standard for the expansion pack.
