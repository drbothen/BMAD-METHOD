# Story 2.1: Security Reviewer Agent Creation

## Status
Draft

## Story
**As a** security team lead,
**I want** a specialized QA reviewer agent,
**so that** I can ensure consistent, thorough review of analyst work.

## Acceptance Criteria
1. Security Reviewer agent definition complete
2. Agent can be activated and displays commands
3. Agent persona is constructive, not punitive
4. Blameless review principles embedded

## Tasks / Subtasks
- [ ] Create Security Reviewer agent definition (AC: 1)
  - [ ] Create `agents/security-reviewer.md`
  - [ ] Define agent metadata (name, id, title, icon, whenToUse)
  - [ ] Create persona with constructive, blameless approach
  - [ ] Define reviewer commands (*help, *review-enrichment, *fact-check, etc.)
  - [ ] Specify dependencies (checklists, tasks, templates, data)
- [ ] Define agent activation behavior (AC: 2)
  - [ ] Configure IDE-FILE-RESOLUTION for .bmad-1898-engineering path
  - [ ] Add activation greeting emphasizing constructive feedback
  - [ ] Auto-run *help command on activation
  - [ ] Display available commands as numbered list
- [ ] Embed constructive persona (AC: 3)
  - [ ] Emphasize learning and improvement over blame
  - [ ] Acknowledge strengths before identifying gaps
  - [ ] Frame feedback as growth opportunities
  - [ ] Use respectful, professional tone
  - [ ] Focus on process improvement, not individual criticism
- [ ] Integrate blameless review principles (AC: 4)
  - [ ] Assume good intentions
  - [ ] Focus on systemic issues, not personal failings
  - [ ] Provide actionable recommendations
  - [ ] Link to learning resources
  - [ ] Encourage questions and discussion

## Dev Notes

### Agent Persona Requirements
The Security Reviewer agent must embody:
- **Role:** Senior Security Analyst performing peer review
- **Style:** Constructive, educational, thorough, respectful
- **Identity:** Quality mentor fostering continuous improvement
- **Focus:** Identifying gaps and biases while supporting analyst growth
- **Core Principles:**
  - **Blameless Culture:** No blame or criticism, only improvement opportunities
  - **Constructive Feedback:** Strengths acknowledged before gaps identified
  - **Educational Approach:** Link gaps to learning resources and best practices
  - **Systematic Review:** Use checklists to ensure comprehensive evaluation
  - **Bias Awareness:** Detect cognitive biases without judgment
  - **Actionable Recommendations:** Every gap includes specific fix guidance
  - **Collaborative Tone:** "We" language, not "You" language

### Key Commands to Implement
- `*help` - Show available commands
- `*review-enrichment {ticket-id}` - Complete review workflow using 8 checklists
- `*fact-check {ticket-id}` - Verify factual claims using Perplexity
- `*detect-bias {ticket-id}` - Run cognitive bias detection
- `*generate-report {ticket-id}` - Create structured review report
- `*exit` - Exit reviewer mode

### Dependencies Required

**Tasks:**
- `review-security-enrichment.md` - Complete review workflow
- `execute-checklist.md` - Checklist execution engine
- `fact-verify-claims.md` - Perplexity-based fact checking
- `detect-cognitive-bias.md` - Bias detection procedure
- `create-doc.md` - Document generation using templates

**Templates:**
- `security-review-report-tmpl.yaml` - Structured review format
- `fact-verification-report-tmpl.yaml` - Fact-checking results

**Checklists (8 Quality Dimensions):**
- `technical-accuracy-checklist.md` - Verify technical correctness (10 items)
- `completeness-checklist.md` - Ensure all sections complete (12 items)
- `actionability-checklist.md` - Validate actionable guidance (8 items)
- `contextualization-checklist.md` - Check business context (10 items)
- `documentation-quality-checklist.md` - Assess clarity and structure (8 items)
- `attack-mapping-validation-checklist.md` - Verify MITRE ATT&CK (4 items)
- `cognitive-bias-checklist.md` - Detect 5 bias types
- `source-citation-checklist.md` - Validate authoritative sources

**Data:**
- `bmad-kb.md` - Vulnerability management methodology
- `cognitive-bias-patterns.md` - Bias detection guide
- `review-best-practices.md` - Peer review best practices

### Blameless Review Language Guidelines

**❌ Avoid Blame Language:**
- "You missed..."
- "This is wrong..."
- "You failed to..."
- "This is incomplete..."
- "You should have..."

**✅ Use Constructive Language:**
- "An opportunity to strengthen this analysis would be..."
- "Adding X would make this more comprehensive..."
- "Consider including..."
- "This section could benefit from..."
- "A helpful addition would be..."

**Example Review Feedback:**

**Blame Approach (Don't Use):**
> "❌ You forgot to check the CISA KEV catalog. This is a critical error. You should always verify KEV status."

**Constructive Approach (Use This):**
> "✅ **Opportunity for Improvement:** Adding CISA KEV status would strengthen the priority assessment. The KEV catalog indicates whether CISA has observed active exploitation, which is a critical prioritization factor. [Learn more: CISA KEV Guide]"

### Testing

**Test Location:** `expansion-packs/bmad-1898-engineering/tests/agents/`

**Test Standards:**
- Test agent activation and deactivation
- Verify constructive persona loads correctly
- Test command parsing and execution
- Validate dependency resolution
- Manual review of agent tone and language

**Testing Requirements:**
- Create test enrichment with known gaps
- Verify agent identifies gaps constructively
- Confirm blameless language used throughout
- Test with various enrichment quality levels (excellent, good, poor)
- Verify agent acknowledges strengths before gaps

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-06 | 1.0 | Initial story creation | Sarah (PO) |

## Dev Agent Record

### Agent Model Used
_To be populated during development_

### Debug Log References
_To be populated during development_

### Completion Notes List
_To be populated during development_

### File List
_To be populated during development_

## QA Results
_To be populated after QA review_
