# Security Event Investigation Review Report Template
# Powered by BMAD‚Ñ¢ Core
#
# This template structures event investigation review findings into comprehensive
# constructive feedback reports with disposition agreement/disagreement tracking.
# It provides blameless, educational feedback that acknowledges strengths first,
# identifies gaps, and provides specific recommendations.

template:
  id: security-event-investigation-review-report-v2
  name: Security Event Investigation Review Report
  version: "2.0"
  output:
    format: markdown
    filename: event-investigation-review-{{ticket_id}}.md
    title: "üîç Event Investigation Review: {{ticket_id}}"

workflow:
  mode: automated
  # No elicitation - template processes data from quality evaluation outputs

instructions: |
  When generating this review report:

  BLAMELESS LANGUAGE REQUIREMENTS:
  - Always acknowledge strengths BEFORE identifying gaps
  - Use "we" language (collaborative), not "you" language (accusatory)
  - Frame gaps as "opportunities for improvement" not "failures" or "errors"
  - Provide specific, actionable recommendations for every gap
  - Link gaps to learning resources (educational approach)
  - Maintain constructive, respectful tone throughout

  AVOID THESE PATTERNS:
  - "You missed..." ‚Üí USE: "An opportunity to strengthen this analysis would be adding..."
  - "This is wrong..." ‚Üí USE: "Consider revising this to reflect..."
  - "You failed to..." ‚Üí USE: "Including X would make this more comprehensive..."
  - "This is incomplete..." ‚Üí USE: "This section could benefit from..."
  - "Critical error..." ‚Üí USE: "Critical issue requiring immediate attention..."

  CONSTRUCTIVE PATTERNS TO USE:
  - "An opportunity to strengthen this analysis would be..."
  - "Adding X would make this more comprehensive..."
  - "Consider including..."
  - "This section could benefit from..."
  - "A helpful addition would be..."
  - "Building on the strong foundation here, we could enhance..."

  DISPOSITION AGREEMENT/DISAGREEMENT HANDLING:
  - If agreeing with analyst disposition: Confirm with supporting evidence
  - If disagreeing: Explain reasoning clearly with specific evidence and logic
  - Avoid blame for disposition disagreements - frame as collaborative analysis
  - Use "Reviewer's assessment suggests..." not "You got it wrong..."

sections:
  - id: review_metadata
    title: Review Metadata
    instruction: |
      Provide review metadata including ticket/alert identifiers, analyst/reviewer names,
      review date, and overall quality score with classification.

      Variables used:
      - ticket_id: JIRA ticket identifier
      - alert_id: Alert rule/signature identifier
      - alert_type: ICS/IDS/SIEM
      - investigation_timestamp: When investigation was performed
      - analyst_name: Name of the analyst who performed investigation
      - reviewer_name: Name of the reviewer
      - review_date: Date of review (YYYY-MM-DD)
      - overall_score: Weighted quality score (0-100)
      - quality_classification: Excellent/Good/Needs Improvement/Inadequate
    template: |
      **Ticket:** {{ticket_id}}<br>
      **Alert ID:** {{alert_id}}<br>
      **Alert Type:** {{alert_type}}<br>
      **Investigation Date:** {{investigation_timestamp}}<br>
      **Analyst:** {{analyst_name}}<br>
      **Reviewer:** {{reviewer_name}}<br>
      **Review Date:** {{review_date}}<br>
      **Overall Quality Score:** {{overall_score}}% ({{quality_classification}})

  - id: executive_summary
    title: Executive Summary
    instruction: |
      Provide a comprehensive multi-paragraph summary (2-4 paragraphs) of review findings:

      Paragraph 1: Acknowledge what was done well (strengths-first approach)
      Paragraph 2: Note key areas for improvement with "Building on..." language
      Paragraph 3 (optional): Additional context or significance

      Then show three-way disposition comparison for quick reference:
      - Analyst Disposition
      - Reviewer Disposition (your independent assessment)
      - Disposition Agreement status

      Use constructive, collaborative tone. Frame gaps as opportunities.

      Variables used:
      - summary_paragraph1: Strengths acknowledgment (what went well)
      - summary_paragraph2: Key improvement areas (building on foundation)
      - summary_paragraph3: Optional additional context
      - analyst_disposition: TP/FP/BTP or "Not Stated"
      - reviewer_disposition: TP/FP/BTP (your independent assessment)
      - disposition_agreement: Agree/Disagree/Cannot Assess (if no analyst disposition)
    template: |
      {{summary_paragraph1}}

      {{summary_paragraph2}}

      {{#if summary_paragraph3}}
      {{summary_paragraph3}}

      {{/if}}
      **Analyst Disposition:** {{analyst_disposition}}<br>
      **Reviewer Disposition:** {{reviewer_disposition}}<br>
      **Disposition Agreement:** {{disposition_agreement}}

  - id: strengths
    title: Strengths & What Went Well
    instruction: |
      Acknowledge what the analyst did well to set a constructive tone. Start reviews
      with positives. Use checkmark emoji (‚úÖ) for each strength.

      This section is critical for blameless feedback - it demonstrates that the reviewer
      recognizes good work before identifying gaps.

      Variables used:
      - strengths: Array of strength statements (3-5 items)

      Note: Use {{#each}} syntax for iteration, access items with {{this}}
    template: |
      {{#each strengths}}
      - ‚úÖ {{this}}
      {{/each}}

  - id: quality_scores
    title: Quality Dimension Scores
    instruction: |
      Display quality dimension scores with weighted contributions showing how each
      dimension contributes to the overall score. Include all seven quality dimensions
      from Story 7.2 event investigation quality checklists.

      The weighted scoring demonstrates transparency in score calculation.

      Variables used:
      - investigation_completeness_score: Score 0-100
      - investigation_completeness_weight: 25
      - investigation_completeness_contribution: Calculated weighted points
      - technical_accuracy_score: Score 0-100
      - technical_accuracy_weight: 20
      - technical_accuracy_contribution: Calculated weighted points
      - disposition_reasoning_score: Score 0-100
      - disposition_reasoning_weight: 20
      - disposition_reasoning_contribution: Calculated weighted points
      - contextualization_score: Score 0-100
      - contextualization_weight: 15
      - contextualization_contribution: Calculated weighted points
      - methodology_score: Score 0-100
      - methodology_weight: 10
      - methodology_contribution: Calculated weighted points
      - documentation_quality_score: Score 0-100
      - documentation_quality_weight: 5
      - documentation_quality_contribution: Calculated weighted points
      - cognitive_bias_score: Score 0-100
      - cognitive_bias_weight: 5
      - cognitive_bias_contribution: Calculated weighted points
      - overall_score: Weighted average score
      - quality_classification: Excellent/Good/Needs Improvement/Inadequate
    template: |
      | Dimension | Score | Weight | Contribution |
      |-----------|-------|--------|--------------|
      | Investigation Completeness | {{investigation_completeness_score}}% | {{investigation_completeness_weight}}% | {{investigation_completeness_contribution}} pts |
      | Technical Accuracy | {{technical_accuracy_score}}% | {{technical_accuracy_weight}}% | {{technical_accuracy_contribution}} pts |
      | Disposition Reasoning | {{disposition_reasoning_score}}% | {{disposition_reasoning_weight}}% | {{disposition_reasoning_contribution}} pts |
      | Contextualization | {{contextualization_score}}% | {{contextualization_weight}}% | {{contextualization_contribution}} pts |
      | Investigation Methodology | {{methodology_score}}% | {{methodology_weight}}% | {{methodology_contribution}} pts |
      | Documentation Quality | {{documentation_quality_score}}% | {{documentation_quality_weight}}% | {{documentation_quality_contribution}} pts |
      | Cognitive Bias | {{cognitive_bias_score}}% | {{cognitive_bias_weight}}% | {{cognitive_bias_contribution}} pts |

      **Overall Quality Score:** {{overall_score}}% ({{quality_classification}})

  - id: critical_issues
    title: Critical Issues (Must Fix)
    instruction: |
      List Critical severity issues that must be fixed before the investigation can proceed.
      These are typically:
      - Incorrect disposition that could lead to security incidents
      - Missing critical evidence or context
      - Factual errors in technical analysis
      - Flawed reasoning that invalidates conclusions

      Use constructive language: describe the issue, explain the impact, provide the fix,
      and link to learning resources. Use red circle emoji (üî¥) to indicate severity.

      Variables used:
      - critical_issues: Array of issue objects with properties:
        - title: Brief issue description
        - location: Where in the investigation (section name)
        - description: What is wrong (factual, not blaming)
        - impact: Why this matters / security impact
        - recommendation: Specific actionable fix
        - resource_title: Learning resource title
        - resource_url: Learning resource URL

      Note: Use {{#each}} with {{this.property}} to access object properties
      Note: {{@index}} is 0-based. Use helper function to add 1 for human-readable numbering
    template: |
      {{#each critical_issues}}
      ### üî¥ Critical Issue {{add @index 1}}: {{this.title}}

      **Location:** {{this.location}}<br>
      **Issue:** {{this.description}}<br>
      **Impact:** {{this.impact}}

      **Recommended Fix:** {{this.recommendation}}

      **Learn More:** [{{this.resource_title}}]({{this.resource_url}})

      {{/each}}

  - id: significant_gaps
    title: Significant Gaps (Should Fix)
    instruction: |
      List Significant severity gaps that should be addressed to improve investigation quality.
      These are typically:
      - Missing recommended evidence sources
      - Incomplete analysis sections
      - Gaps in methodology documentation
      - Missing alternative explanations

      Use constructive language: frame as opportunities for improvement. Use yellow
      circle emoji (üü°) to indicate severity.

      Variables used:
      - significant_gaps: Array of gap objects with same structure as critical_issues
    template: |
      {{#each significant_gaps}}
      ### üü° Significant Gap {{add @index 1}}: {{this.title}}

      **Location:** {{this.location}}<br>
      **Issue:** {{this.description}}<br>
      **Impact:** {{this.impact}}

      **Recommended Fix:** {{this.recommendation}}

      **Learn More:** [{{this.resource_title}}]({{this.resource_url}})

      {{/each}}

  - id: minor_improvements
    title: Minor Improvements (Nice to Have)
    instruction: |
      List Minor improvements that would enhance clarity or completeness but are
      not critical. These are typically:
      - Additional context that would be helpful
      - Documentation formatting improvements
      - Additional evidence sources
      - Enhanced methodology notes

      Use blue circle emoji (üîµ) to indicate severity. Structure is simpler than
      Critical/Significant - just suggestion and benefit.

      Variables used:
      - minor_improvements: Array of improvement objects with properties:
        - title: Brief description
        - description: Suggestion text
        - benefit: Why this would help
    template: |
      {{#each minor_improvements}}
      ### üîµ Minor Improvement {{add @index 1}}: {{this.title}}

      **Suggestion:** {{this.description}}<br>
      **Benefit:** {{this.benefit}}

      {{/each}}

  - id: disposition_assessment
    title: Disposition Assessment
    instruction: |
      Display disposition comparison between analyst and reviewer. This section is
      unique to event investigation reviews and tracks whether the reviewer agrees
      with the analyst's disposition determination.

      If agreement='yes': Confirm why the disposition is correct with supporting evidence
      If agreement='no': Explain reasoning for alternate disposition with specific evidence
      If agreement='uncertain': Explain what additional investigation is needed

      Use constructive, collaborative language. Avoid blame for disagreements.

      Variables used:
      - analyst_disposition: TP/FP/BTP (from investigation)
      - reviewer_disposition: TP/FP/BTP (reviewer's assessment)
      - agreement: yes/no/uncertain
      - reasoning: Explanation with evidence and logic
    template: |
      **Analyst Disposition:** {{analyst_disposition}}<br>
      **Reviewer Disposition:** {{reviewer_disposition}}<br>
      **Agreement:** {{agreement}}

      **Reasoning:**

      {{reasoning}}

  - id: fact_verification
    title: Fact Verification Results
    instruction: |
      Display fact-checking results for key technical claims made in the investigation.
      This builds credibility and demonstrates independent verification of analyst findings.

      Show:
      - Overall accuracy score (percentage of claims verified as correct)
      - Number of claims verified
      - List each claim with verification result (CORRECT/INCORRECT/UNVERIFIABLE)

      This section demonstrates reviewer due diligence in independently verifying
      technical facts using authoritative sources (vendor docs, CVE databases, threat intel).

      Variables used:
      - accuracy_score: Percentage (0-100) of verified claims that are correct
      - claims_verified_count: Number of technical claims reviewed
      - verified_claims: Array of claim objects with properties:
        - claim_number: Sequential number (1, 2, 3...)
        - claim_text: The claim being verified
        - verification_result: CORRECT/INCORRECT/UNVERIFIABLE
        - verification_source: Optional - authoritative source used (e.g., "Datadog docs", "CVE-2023-1234 NVD entry")
    template: |
      **Accuracy Score:** {{accuracy_score}}% {{#if accuracy_score}}({{#if (gte accuracy_score 90)}}all verified claims correct{{else if (gte accuracy_score 75)}}most claims correct{{else}}significant discrepancies{{/if}}){{/if}}<br>
      **Claims Verified:** {{claims_verified_count}}

      {{#each verified_claims}}
      {{#if (eq this.verification_result "CORRECT")}}‚úÖ{{else if (eq this.verification_result "INCORRECT")}}‚ùå{{else}}‚ö†Ô∏è{{/if}} **Claim {{this.claim_number}}:** {{this.claim_text}} - **{{this.verification_result}}**{{#if this.verification_source}} (Source: {{this.verification_source}}){{/if}}<br>
      {{/each}}

      {{#if (lt accuracy_score 100)}}
      **Note:** Factual discrepancies detected. See Critical/Significant Issues sections for details.
      {{else}}
      No factual discrepancies detected - all technical claims in the investigation are accurate.
      {{/if}}

  - id: cognitive_bias_assessment
    title: Cognitive Bias Assessment
    instruction: |
      Display cognitive bias assessment results. If biases were detected, list each
      with type, description, example from the investigation, and debiasing strategy.
      If no biases detected, show positive confirmation.

      Event investigations are particularly susceptible to automation bias (over-reliance
      on alert platform disposition suggestions).

      Use conditional rendering with {{#if}} to check if biases were detected.

      Variables used:
      - cognitive_biases_detected: Boolean (true/false)
      - cognitive_biases: Array of bias objects with properties:
        - type: Bias name (Confirmation Bias, Automation Bias, etc.)
        - description: What this bias is
        - example: Specific example from the investigation
        - mitigation: Debiasing strategy
    template: |
      {{#if cognitive_biases_detected}}
      **Biases Detected:**
      {{#each cognitive_biases}}
      - **{{this.type}}:** {{this.description}}
        - **Example:** {{this.example}}
        - **Debiasing Strategy:** {{this.mitigation}}
      {{/each}}
      {{else}}
      ‚úÖ No significant cognitive biases detected.{{#if cognitive_bias_note}} {{cognitive_bias_note}}{{/if}}
      {{/if}}

  - id: recommendations
    title: Recommended Actions
    instruction: |
      Provide prioritized action items organized into three priority levels with descriptors:
      - Priority 1 (Do First - Critical): Critical fixes, must complete before proceeding
      - Priority 2 (Do Next - Significant): Significant improvements, should complete for quality
      - Priority 3 (When Time Permits - Minor): Minor enhancements, nice to have

      Use clear, actionable language. Each action should be specific enough to execute.

      Variables used:
      - priority1_actions: Array of action strings (critical fixes)
      - priority2_actions: Array of action strings (significant improvements)
      - priority3_actions: Array of action strings (minor enhancements)
    template: |
      **Priority 1 (Do First - Critical):**
      {{#each priority1_actions}}
      - {{this}}
      {{/each}}

      **Priority 2 (Do Next - Significant):**
      {{#each priority2_actions}}
      - {{this}}
      {{/each}}

      **Priority 3 (When Time Permits - Minor):**
      {{#each priority3_actions}}
      - {{this}}
      {{/each}}

  - id: learning_resources
    title: Learning Resources
    instruction: |
      Provide curated learning resources relevant to the identified gaps. Link to:
      - Event investigation best practices
      - Log analysis techniques
      - Disposition determination guidance
      - BMAD-1898 knowledge base articles
      - Security operations references

      Variables used:
      - learning_resources: Array of resource objects with properties:
        - title: Resource title
        - url: Resource URL
        - topic: What this resource teaches
    template: |
      {{#each learning_resources}}
      - [{{this.title}}]({{this.url}}) - {{this.topic}}
      {{/each}}

  - id: next_steps
    title: Next Steps
    instruction: |
      Provide clear next steps for the analyst based on review findings:
      - Critical issues ‚Üí Investigation requires completion/revision
      - Significant gaps ‚Üí Improvements recommended before closure
      - Minor improvements only ‚Üí Optional enhancements
      - Excellent investigation ‚Üí Approved for closure

      Include:
      - Contextual guidance paragraph
      - Checklist-style standard process
      - Estimated time to complete improvements (if rework needed)

      Variables used:
      - next_steps_guidance: Text guidance based on findings severity
      - requires_rework: Boolean - true if critical issues exist
      - estimated_time_minutes_low: Low end of time estimate (e.g., 15)
      - estimated_time_minutes_high: High end of time estimate (e.g., 20)
    template: |
      {{next_steps_guidance}}

      **Standard Process:**
      {{#if requires_rework}}
      - ‚úÖ Address Critical Issues ({{priority1_count}} issues) - Must complete before proceeding
      - ‚¨ú Address Significant Gaps ({{priority2_count}} gaps)
      - ‚¨ú Update investigation documentation in JIRA
      {{#if priority3_actions}}
      - ‚¨ú Consider Minor Improvements (when time permits)
      {{/if}}
      {{#if disposition_agreement}}{{#if (eq disposition_agreement "Disagree")}}
      - ‚¨ú Re-submit for review (Required due to disposition disagreement)
      {{else}}
      - ‚¨ú Re-submit for review (Required for this investigation)
      {{/if}}{{/if}}

      **Estimated Time to Complete:** {{estimated_time_minutes_low}}-{{estimated_time_minutes_high}} minutes{{#if completion_note}} {{completion_note}}{{/if}}
      {{else}}
      - ‚úÖ Investigation quality is {{quality_classification}}
      {{#if priority2_actions}}
      - ‚¨ú Address Significant Gaps (optional improvements)
      {{/if}}
      {{#if priority3_actions}}
      - ‚¨ú Consider Minor Improvements (when time permits)
      {{/if}}
      - ‚¨ú Proceed with ticket closure
      {{/if}}

  - id: reviewer_notes
    title: Reviewer Notes
    instruction: |
      PERSONALIZED free-form notes from the reviewer. This is the human touch that
      transforms a structured report into mentorship and coaching.

      PERSONALIZATION REQUIREMENTS:
      - Address analyst BY NAME (e.g., "Thomas, thank you for...")
      - Reference SPECIFIC work from this investigation (e.g., "your thorough alert metadata documentation...")
      - Acknowledge SPECIFIC strengths (e.g., "The investigation demonstrates strong attention to detail in capturing...")
      - Frame improvement as GROWTH OPPORTUNITY (e.g., "The primary opportunity for growth here is...")
      - End with INVITATION for dialogue (e.g., "Feel free to reach out if you'd like to discuss...")

      Use this section for:
      - Encouragement and coaching (personalized to analyst's work)
      - Recognition of exceptional work or improvement from previous investigations
      - Acknowledgment of challenging investigations
      - Constructive guidance for skill development
      - Building rapport and trust (blameless culture)

      TONE: Supportive, constructive, mentoring, collaborative

      Variables used:
      - analyst_name: Analyst's name for personalization
      - reviewer_name: Your name (sign the notes)
      - reviewer_notes: Free-form text addressing analyst by name with specific feedback
    template: |
      {{reviewer_notes}}

      ‚Äî {{reviewer_name}}
      Security Review Specialist

  - id: attribution
    title: ""
    instruction: |
      Attribution footer for AI-assisted reviews. Shows transparency about tooling
      and collaboration between human reviewer and AI.

      Variables used:
      - co_author_name: Human reviewer's name (e.g., "Joshua Magady")
    template: |

      ---

      ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

      Co-Authored-By: {{co_author_name}}
