"""
Accuracy tests for sampling vs full GLTR analysis.

Tests that sampled analysis produces scores within ±10% of full analysis.
Story 1.4.7: Enable Full Document GLTR Analysis
"""

import pytest
from ai_pattern_analyzer.dimensions.predictability import PredictabilityDimension
from ai_pattern_analyzer.core.analysis_config import AnalysisConfig, AnalysisMode
from ai_pattern_analyzer.core.dimension_registry import DimensionRegistry


@pytest.fixture
def dim():
    """Create PredictabilityDimension instance with clean registry."""
    # Clear registry before each test to avoid duplicate registration errors
    DimensionRegistry.clear()
    return PredictabilityDimension()


class TestDataHelpers:
    """Helper methods for generating test data."""

    @staticmethod
    def _load_sample_chapter() -> str:
        """Generate ~180k char test text (90 pages × 2000 chars/page)."""
        # Use repetitive but varied text
        sentences = [
            "The industrial control system monitors critical infrastructure.",
            "Security operations require continuous vigilance and analysis.",
            "Data patterns reveal insights into system behavior.",
            "Automated detection helps identify potential anomalies.",
        ]
        # 90 pages × 2000 chars/page = 180k chars
        # Each sentence ~60 chars, need ~3000 repetitions
        return " ".join(sentences * 750)  # ~180k chars

    @staticmethod
    def _load_known_ai_text() -> str:
        """Known AI-generated text with expected GLTR ~0.70-0.75."""
        # Highly predictable, repetitive AI-like text
        return """Artificial intelligence represents a transformative paradigm shift
        in computational methodology. It is important to note that machine learning
        algorithms leverage statistical patterns to optimize predictive accuracy.
        Furthermore, deep learning architectures utilize hierarchical representations
        to extract meaningful features from complex datasets. In conclusion, AI systems
        demonstrate remarkable capabilities across diverse application domains.""" * 100

    @staticmethod
    def _load_known_human_text() -> str:
        """Known human text with expected GLTR ~0.45-0.55."""
        # Large collection of unique, natural human sentences (no repetition)
        sentences = [
            "I stumbled upon this old notebook yesterday—pages yellowed, ink fading in spots.",
            "Mom's handwriting is unmistakable.",
            "The cat knocked over my coffee this morning.",
            "Third time this week, honestly.",
            "I'm starting to think it's personal.",
            "Sometimes I wonder what happened to that hiking trail we used to take.",
            "Probably overgrown by now.",
            "My neighbor just got a new dog.",
            "Barks at literally everything.",
            "Even the wind sets it off.",
            "I need to fix that squeaky door hinge.",
            "Been saying that for three months now.",
            "Found an old mixtape in the garage.",
            "No idea what's on it—player's been broken for years.",
            "The grocery store moved the cereal aisle again.",
            "Why do they keep doing that?",
            "I should probably water those plants.",
            "They're looking a bit droopy.",
            "My uncle tells the same three stories at every family gathering.",
            "We all know them by heart now.",
            "There's a weird stain on the ceiling.",
            "Not sure I want to know how it got there.",
            "Left my keys somewhere again.",
            "Checked the usual spots—nothing.",
            "They'll turn up eventually.",
            "The dishwasher's making that noise again.",
            "Guess I'll just ignore it.",
            "Rain finally stopped after four days straight.",
            "Everything's soggy and miserable outside.",
            "My sister called about Thanksgiving plans.",
            "Same debate as last year.",
            "Someone parked in my spot again.",
            "Left a note, but who knows if they'll see it.",
            "The book I ordered still hasn't arrived.",
            "Been two weeks already.",
            "Maybe I should just buy it locally.",
            "Tried that new restaurant downtown.",
            "Food was decent, service was slow.",
            "Probably won't go back though.",
            "My phone battery dies so fast now.",
            "Needs charging twice a day at this point.",
            "Remember when it lasted all day?",
            "Those were the days.",
            "The neighbor's kid is learning trumpet.",
            "It's... not going well.",
            "Earplugs are becoming essential.",
            "I miss the old coffee shop that closed down.",
            "New place just isn't the same.",
            "Coffee tastes different somehow.",
            "Found an old photo album in the closet.",
            "Half the people I don't even recognize anymore.",
            "Time does weird things to memory.",
            "The washing machine is off-balance again.",
            "Sounds like a helicopter taking off.",
            "Need to redistribute the load, I guess.",
            "Traffic was ridiculous this morning.",
            "Took forty minutes for what's usually fifteen.",
            "No idea what the holdup was.",
            "My watch stopped working last Tuesday.",
            "Battery's dead and I keep forgetting to replace it.",
            "Been checking my phone for the time instead.",
            "The mailman delivered someone else's package again.",
            "Wrong address, wrong name, wrong everything.",
            "Happens more often than you'd think.",
            "I can't remember the last time I used that blender.",
            "Just sits there taking up counter space.",
            "Should probably donate it or something.",
            "My computer's acting weird lately.",
            "Freezes randomly, no pattern to it.",
            "Probably time for an update I've been avoiding.",
            "The parking meter ate my quarters.",
            "Didn't even register the payment.",
            "Of course a cop showed up five minutes later.",
            "Started reading that book everyone recommended.",
            "Fifty pages in and I'm not feeling it.",
            "Maybe it gets better?",
            "The lightbulb in the hallway finally died.",
            "Been flickering for weeks.",
            "Guess I have to change it now.",
            "Someone left their shopping cart in the parking spot next to mine.",
            "Right up against my door.",
            "Had to climb in from the passenger side.",
            "My coworker microwaved fish again.",
            "The whole office smells terrible.",
            "How is this still happening?",
            "The remote control disappeared into the couch cushions.",
            "It's like the Bermuda Triangle in there.",
            "Gave up and used my phone instead.",
        ]
        return " ".join(sentences)


class TestSamplingAccuracy:
    """Test sampling doesn't bias scores."""

    @pytest.mark.slow
    def test_sampled_vs_full_within_10_percent(self, dim):
        """Test sampled analysis within ±10% of full analysis."""

        helpers = TestDataHelpers()
        test_text = helpers._load_known_ai_text()  # Known AI score ~0.75

        # Full analysis
        full_config = AnalysisConfig(mode=AnalysisMode.FULL)
        full_result = dim.analyze(test_text, config=full_config)
        full_score = full_result['gltr_top10_percentage']

        # Sampled analysis
        sampled_config = AnalysisConfig(mode=AnalysisMode.SAMPLING, sampling_sections=5)
        sampled_result = dim.analyze(test_text, config=sampled_config)
        sampled_score = sampled_result['gltr_top10_percentage']

        # Verify within ±10%
        difference = abs(full_score - sampled_score)
        assert difference <= 0.10, \
            f"Sampled score {sampled_score:.3f} differs from full {full_score:.3f} by {difference:.3f} (>10%)"

    @pytest.mark.slow
    def test_adaptive_vs_full_within_10_percent(self, dim):
        """Test ADAPTIVE mode within ±10% of full analysis."""

        helpers = TestDataHelpers()
        test_text = helpers._load_known_human_text()  # Known human score ~0.50

        # Full analysis
        full_config = AnalysisConfig(mode=AnalysisMode.FULL)
        full_result = dim.analyze(test_text, config=full_config)
        full_score = full_result['gltr_top10_percentage']

        # ADAPTIVE analysis
        adaptive_config = AnalysisConfig(mode=AnalysisMode.ADAPTIVE)
        adaptive_result = dim.analyze(test_text, config=adaptive_config)
        adaptive_score = adaptive_result['gltr_top10_percentage']

        # Verify within ±10%
        difference = abs(full_score - adaptive_score)
        assert difference <= 0.10, \
            f"ADAPTIVE score {adaptive_score:.3f} differs from full {full_score:.3f} by {difference:.3f} (>10%)"

    def test_sampling_detects_ai_text(self, dim):
        """Test sampling correctly identifies AI text."""
        config = AnalysisConfig(mode=AnalysisMode.SAMPLING, sampling_sections=5)

        helpers = TestDataHelpers()
        ai_text = helpers._load_known_ai_text()
        result = dim.analyze(ai_text, config=config)

        # AI text should have high top-10 percentage (>0.60)
        assert result['gltr_top10_percentage'] > 0.60, \
            f"AI text scored {result['gltr_top10_percentage']:.3f}, expected >0.60"

    def test_sampling_detects_human_text(self, dim):
        """Test sampling correctly identifies human text."""
        config = AnalysisConfig(mode=AnalysisMode.SAMPLING, sampling_sections=5)

        helpers = TestDataHelpers()
        human_text = helpers._load_known_human_text()
        result = dim.analyze(human_text, config=config)

        # Human text should have lower top-10 percentage (<0.60)
        assert result['gltr_top10_percentage'] < 0.60, \
            f"Human text scored {result['gltr_top10_percentage']:.3f}, expected <0.60"

    @pytest.mark.slow
    def test_multiple_samples_improves_accuracy(self, dim):
        """Test that more samples produce results closer to full analysis."""

        helpers = TestDataHelpers()
        test_text = helpers._load_known_ai_text()

        # Full analysis (baseline)
        full_config = AnalysisConfig(mode=AnalysisMode.FULL)
        full_result = dim.analyze(test_text, config=full_config)
        full_score = full_result['gltr_top10_percentage']

        # 3 samples
        config_3 = AnalysisConfig(mode=AnalysisMode.SAMPLING, sampling_sections=3)
        result_3 = dim.analyze(test_text, config=config_3)
        diff_3 = abs(result_3['gltr_top10_percentage'] - full_score)

        # 10 samples
        config_10 = AnalysisConfig(mode=AnalysisMode.SAMPLING, sampling_sections=10)
        result_10 = dim.analyze(test_text, config=config_10)
        diff_10 = abs(result_10['gltr_top10_percentage'] - full_score)

        # More samples should be closer to full analysis
        # Allow some variance, but generally 10 samples should be better
        assert diff_10 <= diff_3 * 1.5, \
            f"10 samples (diff={diff_10:.3f}) not better than 3 samples (diff={diff_3:.3f})"

    def test_consistent_results_across_runs(self, dim):
        """Test that analysis produces consistent results on same text."""
        config = AnalysisConfig(mode=AnalysisMode.FAST)

        text = "word " * 500

        # Run analysis twice
        result1 = dim.analyze(text, config=config)
        result2 = dim.analyze(text, config=config)

        # Results should be identical (deterministic)
        assert result1['gltr_top10_percentage'] == result2['gltr_top10_percentage']
        assert result1['gltr_mean_rank'] == result2['gltr_mean_rank']

    @pytest.mark.slow
    def test_sampling_across_document_positions(self, dim):
        """Test that sampling covers beginning, middle, and end of document."""
        config = AnalysisConfig(mode=AnalysisMode.ADAPTIVE)

        # Create document with distinct sections
        beginning = "The beginning text has specific characteristics. " * 100
        middle = "The middle section contains different patterns. " * 100
        end = "The ending portion shows unique features. " * 100
        text = beginning + middle + end

        result = dim.analyze(text, config=config)

        # With ADAPTIVE mode and long text, should sample multiple sections
        assert result['samples_analyzed'] >= 3, \
            "Expected multiple samples to cover document positions"
        assert result['coverage_percentage'] > 5.0, \
            "Expected reasonable coverage across document"
